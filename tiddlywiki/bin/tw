#!/usr/bin/env python3

import os
import sys
import subprocess
import tempfile
import base64
import urllib.request
import urllib.error
import urllib.parse
import re
from collections import OrderedDict

# Import filter module
import tw_filter

# Global cache to store original field orders for tiddlers
# Key: (wiki_path, tiddler_title) -> List of field names in original order
_original_field_orders = {}

# Pre-compiled regex patterns for performance
_STORE_AREA_PATTERN = re.compile(r'<div id="storeArea"[^>]*>')
_DIV_PATTERN = re.compile(r'<div(?:\s+[^>]*)?>|</div>', re.DOTALL)
_TIDDLER_DIV_PATTERN = re.compile(r'<div\s+([^>]+?)>', re.DOTALL)
_ATTR_PATTERN = re.compile(r'(\w+)=(["\'])([^\2]*?)\2')
_TITLE_ATTR_PATTERN = re.compile(r'<div[^>]+title="([^"]*)"', re.DOTALL)
_PRE_PATTERN = re.compile(r'<pre>(.*?)</pre>', re.DOTALL)
_JSON_TITLE_PATTERN = re.compile(r'"title"\s*:\s*"([^"]*)"')

# Mapping of file extensions to MIME types
EXT_TO_MIME_TYPE = {
    # Images
    '.apng': 'image/apng',
    '.avif': 'image/avif',
    '.bmp': 'image/bmp',
    '.gif': 'image/gif',
    '.ico': 'image/vnd.microsoft.icon',
    '.jpeg': 'image/jpeg',
    '.jpg': 'image/jpeg',
    '.png': 'image/png',
    '.svg': 'image/svg+xml',
    '.tif': 'image/tiff',
    '.tiff': 'image/tiff',
    '.webp': 'image/webp',

    # Videos
    '.avi': 'video/x-msvideo',
    '.3gp': 'video/3gpp',
    '.3g2': 'video/3gpp2',
    '.mp4': 'video/mp4',
    '.mpeg': 'video/mpeg',
    '.mpg': 'video/mpeg',
    '.mov': 'video/quicktime',
    '.ogv': 'video/ogg',
    '.ts': 'video/mp2t',
    '.webm': 'video/webm',
    '.mkv': 'video/x-matroska',

    # Audio
    '.aac': 'audio/aac',
    '.mid': 'audio/midi',
    '.midi': 'audio/midi',
    '.mp3': 'audio/mpeg',
    '.oga': 'audio/ogg',
    '.opus': 'audio/ogg',
    '.wav': 'audio/wav',
    '.weba': 'audio/webm',
    '.m4a': 'audio/mp4',

    # Documents
    '.doc': 'application/msword',
    '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
    '.pdf': 'application/pdf',
    '.ppt': 'application/vnd.ms-powerpoint',
    '.pptx': 'application/vnd.openxmlformats-officedocument.presentationml.presentation',
    '.xls': 'application/vnd.ms-excel',
    '.xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
    '.odt': 'application/vnd.oasis.opendocument.text',
    '.ods': 'application/vnd.oasis.opendocument.spreadsheet',
    '.odp': 'application/vnd.oasis.opendocument.presentation',

    # Archives
    '.7z': 'application/x-7z-compressed',
    '.bz': 'application/x-bzip',
    '.bz2': 'application/x-bzip2',
    '.gz': 'application/gzip',
    '.rar': 'application/vnd.rar',
    '.tar': 'application/x-tar',
    '.zip': 'application/zip',

    # Web & Code
    '.css': 'text/css',
    '.csv': 'text/csv',
    '.html': 'text/html',
    '.htm': 'text/html',
    '.js': 'text/javascript',
    '.mjs': 'text/javascript',
    '.json': 'application/json',
    '.xml': 'application/xml',
    '.txt': 'text/plain',
    '.md': 'text/markdown',
    '.markdown': 'text/markdown',

    # Programming
    '.py': 'text/x-python',
    '.sh': 'text/x-shellscript',
    '.bash': 'text/x-shellscript',
    '.yaml': 'text/x-yaml',
    '.yml': 'text/x-yaml',
    '.sql': 'text/x-sql',
}

# Mapping of TiddlyWiki MIME types to Neovim filetypes
MIME_TO_VIM_FILETYPE = {
    # TiddlyWiki formats
    'text/vnd.tiddlywiki': 'markdown',
    'text/x-tiddlywiki': 'markdown',
    'text/vnd.tiddlywiki-multiple': 'markdown',

    # Markup formats
    'text/markdown': 'markdown',
    'text/html': 'html',
    'text/plain': 'text',

    # Stylesheet
    'text/css': 'css',

    # Programming languages
    'application/javascript': 'javascript',
    'application/json': 'json',
    'application/x-tiddler-dictionary': 'text',
    'text/x-python': 'python',
    'text/x-shellscript': 'sh',
    'text/xml': 'xml',
    'application/xml': 'xml',
    'text/x-yaml': 'yaml',
    'text/x-sql': 'sql',
}

VERBOSE = False

# Commands that mutate wiki content
MUTATING_COMMANDS = {
    "set",
    "rm",
    "touch",
    "insert",
    "replace",
    "append",
    "install_plugin",
    "import-dir",
}

# Commands that do not accept a wiki path
NO_WIKI_COMMANDS = {"init", "filetype-map", "mimetype"}

# Commands not safe/sensible inside ops batches
OPS_DISALLOWED_COMMANDS = {
    "ops",
    "init",
    "filetype-map",
    "mimetype",
    "serve",
    "webdav",
    "edit",
    "install_plugin",
    "export-dir",
    "import-dir",
}

# Commands supported by the in-memory transactional ops engine
OPS_TRANSACTION_SUPPORTED_COMMANDS = {
    "ls",
    "cat",
    "json",
    "get",
    "set",
    "rm",
    "touch",
    "insert",
    "replace",
    "append",
    "detect",
}

def verbose_print(*args, **kwargs):
    if VERBOSE:
        print(*args, **kwargs)

def record_field_order(wiki_path, tiddler_title, field_order):
    """Record the original field order for a tiddler"""
    key = (wiki_path, tiddler_title)
    _original_field_orders[key] = field_order

def get_field_order(wiki_path, tiddler_title):
    """Get the original field order for a tiddler, or None if not recorded"""
    key = (wiki_path, tiddler_title)
    return _original_field_orders.get(key)

def reorder_tiddler_fields(tiddler, wiki_path, tiddler_title):
    """Reorder tiddler fields to match original order if available.

    If original order is known, reorder fields to match.
    New fields (not in original) are appended at the end.
    """
    original_order = get_field_order(wiki_path, tiddler_title)

    if not original_order:
        # No original order recorded; mimic TiddlyWiki's construction order:
        # creation fields first, then user fields, then modification fields.
        creation_fields = ['created', 'creator']
        modification_fields = ['modified', 'modifier']

        ordered = OrderedDict()

        for field in creation_fields:
            if field in tiddler:
                ordered[field] = tiddler[field]

        for field, value in tiddler.items():
            if field in creation_fields or field in modification_fields:
                continue
            ordered[field] = value

        for field in modification_fields:
            if field in tiddler:
                ordered[field] = tiddler[field]

        return ordered

    # Create new dict with fields in original order
    reordered = OrderedDict()

    # Add fields in original order
    for field in original_order:
        if field in tiddler:
            reordered[field] = tiddler[field]

    # Add any new fields that weren't in original order
    for field, value in tiddler.items():
        if field not in reordered:
            reordered[field] = value

    return reordered

def is_remote_wiki(wiki_path):
    """Return True if the wiki path is an HTTP(S) URL."""
    if not wiki_path:
        return False
    parsed = urllib.parse.urlparse(wiki_path)
    return parsed.scheme in ('http', 'https')

def ensure_local_wiki(wiki_path):
    """Exit if the wiki path points to a remote URL."""
    if is_remote_wiki(wiki_path):
        print("Error: Writing to remote wikis is not supported. Download the wiki locally first.", file=sys.stderr)
        sys.exit(1)

def read_wiki_content(wiki_path):
    """Read wiki content from a local file or remote URL."""
    if is_remote_wiki(wiki_path):
        try:
            with urllib.request.urlopen(wiki_path, timeout=10) as response:
                encoding = response.headers.get_content_charset() or 'utf-8'
                return response.read().decode(encoding, errors='replace')
        except urllib.error.URLError as e:
            print(f"Error: Failed to fetch remote wiki: {e}", file=sys.stderr)
            sys.exit(1)
        except Exception as e:
            print(f"Error: Failed to read remote wiki: {e}", file=sys.stderr)
            sys.exit(1)

    with open(wiki_path, 'r', encoding='utf-8') as f:
        return f.read()

def get_wiki_path(wiki_path=None):
    """Get the wiki path from the argument.

    Args:
        wiki_path: Optional wiki path argument.

    Returns:
        Absolute path to the wiki file or a remote URL.
    """
    if not wiki_path:
        print("Error: Wiki path not provided", file=sys.stderr)
        sys.exit(1)

    # Expand ~ to home directory
    wiki_path = os.path.expanduser(wiki_path)

    if is_remote_wiki(wiki_path):
        return wiki_path

    if not os.path.exists(wiki_path):
        print(f"Error: Wiki path does not exist: {wiki_path}", file=sys.stderr)
        sys.exit(1)

    return os.path.abspath(wiki_path)

def extract_tiddler_stores(content, target_title=None):
    """Extract tiddler store JSON arrays from HTML content.

    Args:
        content: HTML content of the wiki file
        target_title: If provided, stop parsing after finding a store with this tiddler

    Returns list of store dictionaries with 'start', 'end', and 'tiddlers' keys.
    If target_title is provided, may return early with partial results.
    """
    import json

    stores = []
    # Find the start of each tiddler store
    pattern = r'<script class="tiddlywiki-tiddler-store" type="application/json">'

    pos = 0
    while True:
        start_match = content.find(pattern, pos)
        if start_match == -1:
            break

        # Find the start of the JSON array
        json_start = content.find('[', start_match)
        if json_start == -1:
            break

        # Find the matching closing tag
        end_tag = '</script>'
        end_match = content.find(end_tag, json_start)
        if end_match == -1:
            break

        # Extract the JSON (trim whitespace)
        json_str = content[json_start:end_match].strip()

        try:
            # Use strict=False to allow control characters like tabs/newlines in strings
            tiddlers = json.loads(json_str, strict=False)
            stores.append({
                'start': start_match,
                'end': end_match + len(end_tag),
                'tiddlers': tiddlers
            })

            # Early exit if we found the target tiddler
            if target_title:
                for tiddler in tiddlers:
                    if tiddler.get('title') == target_title:
                        return stores

        except json.JSONDecodeError as e:
            print(f"Warning: Failed to parse tiddler store: {e}", file=sys.stderr)

        pos = end_match + len(end_tag)

    return stores

def detect_wiki_format(content):
    """Detect whether a wiki uses modern (JSON) or legacy (div) format.

    Returns:
        'modern': Uses <script class="tiddlywiki-tiddler-store"> format
        'legacy': Uses <div id="storeArea"> format

    Raises:
        SystemExit if neither format is detected
    """
    has_modern = '<script class="tiddlywiki-tiddler-store"' in content
    has_legacy = '<div id="storeArea"' in content

    if has_modern:
        return 'modern'
    elif has_legacy:
        return 'legacy'
    else:
        print("Error: Could not detect wiki format (neither modern JSON stores nor legacy storeArea found)", file=sys.stderr)
        sys.exit(1)

def detect_format_streaming(filepath):
    """Detect wiki format by streaming file with early exit.

    This is more efficient than loading the entire file for large wikis.
    Returns as soon as either format marker is found.

    Args:
        filepath: Path to the wiki HTML file

    Returns:
        'modern': Uses <script class="tiddlywiki-tiddler-store"> format
        'legacy': Uses <div id="storeArea"> format

    Raises:
        SystemExit if file cannot be read or no format detected
    """
    CHUNK_SIZE = 1024 * 1024  # 1MB chunks
    OVERLAP = 1024  # Keep 1KB overlap for patterns split across chunks

    modern_marker = b'<script class="tiddlywiki-tiddler-store"'
    legacy_marker = b'<div id="storeArea"'

    try:
        with open(filepath, 'rb') as f:
            previous_chunk_end = b''

            while True:
                chunk = f.read(CHUNK_SIZE)
                if not chunk:
                    break

                # Check in overlap region + current chunk
                search_region = previous_chunk_end + chunk

                if modern_marker in search_region:
                    return 'modern'
                if legacy_marker in search_region:
                    return 'legacy'

                # Save end of chunk for overlap check
                previous_chunk_end = chunk[-OVERLAP:] if len(chunk) >= OVERLAP else chunk

        # Reached end of file without finding a format marker
        print("Error: Could not detect wiki format (neither modern JSON stores nor legacy storeArea found)", file=sys.stderr)
        sys.exit(1)

    except IOError as e:
        print(f"Error: Could not read file: {e}", file=sys.stderr)
        sys.exit(1)

def extract_titles_only_legacy(content):
    """Extract only tiddler titles from legacy format - FAST path for ls.

    This is much faster than extract_legacy_tiddlers() because it only
    extracts titles without parsing full tiddler content, attributes, or HTML.

    Returns:
        List of tiddler title strings
    """
    import html

    # Find storeArea
    store_match = _STORE_AREA_PATTERN.search(content)
    if not store_match:
        return []

    # Extract all title="..." attributes from divs in storeArea
    # This is much faster than full parsing
    titles = []
    for match in _TITLE_ATTR_PATTERN.finditer(content, store_match.end()):
        title = html.unescape(match.group(1))
        titles.append(title)

    return titles

def extract_titles_only_modern(content):
    """Extract only tiddler titles from modern JSON format - FAST path for ls.

    This extracts titles using regex instead of parsing full JSON,
    which is much faster for large wikis with many tiddlers.

    Returns:
        List of tiddler title strings
    """
    # Find all "title":"..." in JSON stores
    titles = []
    for match in _JSON_TITLE_PATTERN.finditer(content):
        # JSON strings don't need HTML unescaping, but may have escaped quotes
        title = match.group(1).replace('\\"', '"')
        titles.append(title)

    return titles

def extract_legacy_tiddlers(content, target_title=None):
    """Extract tiddlers from legacy <div id="storeArea"> format.

    Args:
        content: HTML content of the wiki file
        target_title: If provided, stop parsing after finding this tiddler (for performance)

    Returns a list of tiddler dictionaries in the same format as modern wikis.
    If target_title is provided, returns a list with at most one tiddler.
    """
    import html

    # Find the storeArea div
    store_match = _STORE_AREA_PATTERN.search(content)
    if not store_match:
        return []

    store_start = store_match.end()

    # Find the closing </div> for storeArea
    div_count = 1
    store_end = None

    for match in _DIV_PATTERN.finditer(content, store_start):
        tag = match.group()
        if tag.startswith('</'):
            div_count -= 1
            if div_count == 0:
                store_end = match.start()
                break
        else:
            div_count += 1

    if store_end is None:
        print("Error: Could not find closing tag for storeArea", file=sys.stderr)
        sys.exit(1)

    # Extract the store area content
    store_content = content[store_start:store_end]

    # Parse individual tiddler divs
    tiddlers = []

    # Build list of all div positions (open and close) in store_content
    all_divs = []
    for match in _DIV_PATTERN.finditer(store_content):
        tag = match.group()
        all_divs.append({
            'pos': match.start(),
            'end': match.end(),
            'is_close': tag.startswith('</')
        })

    # Find all tiddler start positions
    tiddler_starts = []
    for match in _TIDDLER_DIV_PATTERN.finditer(store_content):
        tiddler_starts.append({
            'pos': match.start(),
            'end': match.end(),
            'attr_string': match.group(1)
        })

    # For each tiddler, find its closing tag
    for tidx, tiddler_info in enumerate(tiddler_starts):
        tiddler_start_pos = tiddler_info['pos']
        tiddler_content_start = tiddler_info['end']
        attr_string = tiddler_info['attr_string']

        # Parse attributes
        tiddler = {}
        for attr_match in _ATTR_PATTERN.finditer(attr_string):
            attr_name = attr_match.group(1)
            attr_value = attr_match.group(3)
            # Decode HTML entities in attribute values
            attr_value = html.unescape(attr_value)
            tiddler[attr_name] = attr_value

        # Only process tiddlers with a title
        if 'title' not in tiddler:
            continue

        # Find the matching closing </div> for this tiddler
        nest_count = 1
        tiddler_end_pos = None

        for div_info in all_divs:
            if div_info['pos'] <= tiddler_content_start:
                continue

            if div_info['is_close']:
                nest_count -= 1
                if nest_count == 0:
                    tiddler_end_pos = div_info['pos']
                    break
            else:
                nest_count += 1

        if tiddler_end_pos is None:
            # Couldn't find closing tag
            continue

        # Extract tiddler content
        tiddler_content_html = store_content[tiddler_content_start:tiddler_end_pos]

        # Extract text from <pre> tags if present
        pre_match = _PRE_PATTERN.search(tiddler_content_html)
        if pre_match:
            text_content = pre_match.group(1)
            # Decode HTML entities in the text
            text_content = html.unescape(text_content)
            tiddler['text'] = text_content
        elif tiddler_content_html.strip():
            # If no <pre> tag, use the content directly (but this is rare)
            text_content = html.unescape(tiddler_content_html.strip())
            # Only set text if there's actual content and doesn't look like HTML tags
            if text_content and not text_content.startswith('<'):
                tiddler['text'] = text_content

        tiddlers.append(tiddler)

        # Early exit if we found the target tiddler
        if target_title and tiddler.get('title') == target_title:
            return [tiddler]

    return tiddlers

def load_all_tiddlers(wiki_path, titles_only=False, target_title=None):
    """Load tiddlers from wiki file.

    Args:
        wiki_path: Path to the wiki HTML file
        titles_only: If True, use fast path to extract only titles (for ls command)
        target_title: If provided, stop parsing after finding this tiddler (for cat/get)

    Returns:
        If titles_only=True: list of title strings
        Otherwise: list of tiddler dictionaries
    """
    content = read_wiki_content(wiki_path)

    # Detect format
    wiki_format = detect_wiki_format(content)

    # Fast path for titles only
    if titles_only:
        if wiki_format == 'modern':
            return extract_titles_only_modern(content)
        else:  # legacy
            return extract_titles_only_legacy(content)

    # Full parsing path
    if wiki_format == 'modern':
        stores = extract_tiddler_stores(content, target_title=target_title)

        if not stores:
            print("Error: Could not find any tiddler stores in wiki", file=sys.stderr)
            sys.exit(1)

        # Collect all tiddlers from all stores and record their field order
        all_tiddlers = []
        for store in stores:
            all_tiddlers.extend(store['tiddlers'])
            # Record the field order for each tiddler as it appears in the file
            for tiddler in store['tiddlers']:
                if 'title' in tiddler:
                    field_order = list(tiddler.keys())
                    record_field_order(wiki_path, tiddler['title'], field_order)

    elif wiki_format == 'legacy':
        all_tiddlers = extract_legacy_tiddlers(content, target_title=target_title)

        if not all_tiddlers:
            print("Error: Could not find any tiddlers in wiki", file=sys.stderr)
            sys.exit(1)

        # Record field order for legacy tiddlers too
        for tiddler in all_tiddlers:
            if 'title' in tiddler:
                field_order = list(tiddler.keys())
                record_field_order(wiki_path, tiddler['title'], field_order)

    if not all_tiddlers:
        print("Error: Could not find any tiddlers in wiki", file=sys.stderr)
        sys.exit(1)

    return all_tiddlers

def list_tiddlers(wiki_path):
    # Use fast path to extract only titles
    titles = load_all_tiddlers(wiki_path, titles_only=True)

    # Sort alphabetically
    titles.sort()

    # Print all tiddler titles
    for title in titles:
        print(title)

def format_tiddler_cat(tiddler):
    """Return tiddler content in tw cat format."""
    lines = []

    if 'title' in tiddler:
        lines.append(f"title: {tiddler['title']}")

    for key, value in sorted(tiddler.items()):
        if key not in ('text', 'title'):
            lines.append(f"{key}: {value}")

    if 'text' in tiddler:
        lines.append('')
        lines.append(tiddler['text'])

    return '\n'.join(lines)

def _encode_tiddler_title_segment(title):
    """Encode tiddler titles similar to TiddlyWiki filesystem filenames.

    This is used for filesystem-based tiddler storage (not WebDAV).
    For WebDAV, use encode_tiddler_title_for_path instead."""
    segment = title
    segment = segment.replace('/', '_').replace('\\', '_')
    segment = re.sub(r'^(con|prn|aux|nul|com[0-9]|lpt[0-9])$', r'_\1_', segment, flags=re.IGNORECASE)
    segment = re.sub(r'^ +', lambda m: '_' * len(m.group(0)), segment)
    if not re.match(r'^\.\.{0,1}[/\\]', title):
        segment = re.sub(r'^\.+', lambda m: '_' * len(m.group(0)), segment)
    segment = re.sub(r'[\x00-\x1f\x80-\x9f]', '_', segment)
    segment = re.sub(r'[<>~:"|?*^%]', '_', segment)
    if not segment or re.match(r'^_+$', segment):
        segment = '-'.join(str(ord(c)) for c in title)
    return segment

def encode_tiddler_title_for_path(title):
    """Encode a tiddler title into a WebDAV-safe path segment.

    Uses URL percent-encoding for a reversible transformation.
    Safe characters (unreserved in RFC 3986): A-Z a-z 0-9 - . _ ~

    Note: We don't include $ in safe chars because macOS has issues with
    paths like $%3A%2Fcore (decodes to $:/core which is invalid on APFS/HFS+)."""
    return urllib.parse.quote(title, safe='-_.~')

def decode_tiddler_title_from_path(segment):
    """Decode a WebDAV path segment back to the original title.

    This is the inverse of encode_tiddler_title_for_path."""
    return urllib.parse.unquote(segment)

def cat_tiddler(wiki_path, tiddler_title):
    # Use early-exit optimization to stop parsing after finding target
    all_tiddlers = load_all_tiddlers(wiki_path, target_title=tiddler_title)

    # Find the tiddler with matching title
    tiddler = None
    for t in all_tiddlers:
        if t.get('title') == tiddler_title:
            tiddler = t
            break

    if not tiddler:
        print(f"Error: Tiddler '{tiddler_title}' not found", file=sys.stderr)
        sys.exit(1)

    print(format_tiddler_cat(tiddler))

def edit_tiddler(wiki_path, tiddler_title):
    """Open a tiddler in $EDITOR for editing in YAML-style format"""
    import threading
    import time

    ensure_local_wiki(wiki_path)

    # Check if EDITOR environment variable is set
    editor = os.environ.get('EDITOR')
    if not editor:
        # Fall back to common editors if EDITOR is not set
        for fallback_editor in ['nvim', 'vim', 'nano', 'emacs', 'vi']:
            import shutil
            if shutil.which(fallback_editor):
                editor = fallback_editor
                break

    if not editor:
        print("Error: $EDITOR environment variable is not set and no fallback editor found", file=sys.stderr)
        sys.exit(1)

    # Use early-exit optimization to stop parsing after finding target
    all_tiddlers = load_all_tiddlers(wiki_path, target_title=tiddler_title)

    # Find the tiddler with matching title
    tiddler = None
    is_new_tiddler = False
    for t in all_tiddlers:
        if t.get('title') == tiddler_title:
            tiddler = t
            break

    # If tiddler doesn't exist, create a template
    initial_missing_timestamps = False

    if not tiddler:
        tiddler = {
            "title": tiddler_title,
            "created": get_tiddlywiki_timestamp(),
            "modified": get_tiddlywiki_timestamp()
        }
        is_new_tiddler = True
    else:
        initial_missing_timestamps = ('created' not in tiddler) or ('modified' not in tiddler)
        # Ensure timestamps exist so the watcher can safely insert them
        if 'created' not in tiddler:
            tiddler['created'] = get_tiddlywiki_timestamp()
        if 'modified' not in tiddler:
            tiddler['modified'] = get_tiddlywiki_timestamp()

    # Store the original tiddler's meaningful content (excluding timestamps) for comparison
    def get_editable_fields(t):
        """Get tiddler fields excluding created/modified timestamps"""
        result = {}
        for key, value in t.items():
            if key not in ('created', 'modified'):
                result[key] = value
        return result

    original_editable = get_editable_fields(tiddler)

    # Create a temporary file to edit
    temp_fd, temp_path = tempfile.mkstemp(suffix='.txt', text=True)

    try:
        # Write tiddler in cat format to temp file
        # NOTE: We exclude 'created' and 'modified' so that replace_tiddler
        # can detect whether content changed and update the timestamp appropriately
        with os.fdopen(temp_fd, 'w', encoding='utf-8') as f:
            # Write title first
            if 'title' in tiddler:
                f.write(f"title: {tiddler['title']}\n")

            # Write all other fields except 'text', 'title', 'created', and 'modified'
            for key, value in sorted(tiddler.items()):
                if key not in ('text', 'title', 'created', 'modified'):
                    f.write(f"{key}: {value}\n")

            # Write the text content after a blank line
            if 'text' in tiddler:
                f.write('\n')
                f.write(tiddler['text'])

        # Start background watcher for live updates
        stop_watching = threading.Event()
        last_mtime = [os.path.getmtime(temp_path)]
        # Initialize with current content to avoid treating initial write-back as a change
        with open(temp_path, 'r', encoding='utf-8') as f:
            initial_content = f.read()
        last_content = [initial_content]

        def watch_and_update():
            """Background thread that watches for file changes and updates the tiddler"""
            import io
            import contextlib

            while not stop_watching.is_set():
                time.sleep(0.5)  # Poll every 0.5 seconds
                try:
                    current_mtime = os.path.getmtime(temp_path)
                    if current_mtime != last_mtime[0]:
                        last_mtime[0] = current_mtime

                        # Read the updated content
                        with open(temp_path, 'r', encoding='utf-8') as f:
                            updated_content = f.read()

                        # Check if content actually changed (not just mtime)
                        if updated_content == last_content[0]:
                            # Content is identical, skip update
                            continue

                        last_content[0] = updated_content

                        # Add timestamps and update the wiki
                        updated_content_lines = updated_content.split('\n')
                        # Find where to insert timestamps (before the empty line or text)
                        insert_pos = 0
                        for i, line in enumerate(updated_content_lines):
                            if line.strip() == '':
                                insert_pos = i
                                break

                        # Reconstruct content with timestamps
                        new_lines = updated_content_lines[:insert_pos]
                        # Always add created timestamp
                        new_lines.insert(insert_pos, f"created: {tiddler['created']}")
                        # replace_tiddler will update modified timestamp automatically
                        new_lines.extend(updated_content_lines[insert_pos:])
                        content_with_timestamps = '\n'.join(new_lines)

                        # Update the tiddler in the wiki (suppress output)
                        with contextlib.redirect_stdout(io.StringIO()):
                            replace_tiddler(wiki_path, content_with_timestamps, update_modified=True)
                except (FileNotFoundError, OSError):
                    # File was deleted or other OS error, stop watching
                    break

        watcher = threading.Thread(target=watch_and_update, daemon=True)
        watcher.start()

        # Open the file in the editor
        # Split the editor command in case it has arguments (e.g., "emacs -nw")
        editor_parts = editor.split()

        # Get the tiddler type and map to vim filetype
        tiddler_type = tiddler.get('type', 'text/vnd.tiddlywiki')
        vim_filetype = MIME_TO_VIM_FILETYPE.get(tiddler_type, 'text')

        # If using nvim/vim, add filetype command
        editor_base = editor_parts[0].lower() if editor_parts else ''
        if 'vim' in editor_base or 'nvim' in editor_base:
            # Add vim command to set filetype
            editor_parts = editor_parts + ['-c', f'set filetype={vim_filetype}']

            # Check if this is a journal tiddler (YYYY-MM-DD format)
            import re
            if re.match(r'^\d{4}-\d{2}-\d{2}$', tiddler_title):
                # Journal-specific settings: hide line numbers, minimal statusline
                editor_parts = editor_parts + [
                    '-c', 'set nonumber norelativenumber',
                    '-c', 'set laststatus=0'  # Hide statusline entirely
                ]

        result = subprocess.run(editor_parts + [temp_path], check=False)

        # Stop the watcher
        stop_watching.set()
        watcher.join(timeout=2)

        if result.returncode != 0:
            print(f"Error: Editor exited with status {result.returncode}", file=sys.stderr)
            sys.exit(1)

        # Read the final edited content
        with open(temp_path, 'r', encoding='utf-8') as f:
            edited_content = f.read()

        # Parse the edited content to check what actually changed
        edited_lines = edited_content.split('\n')
        edited_tiddler = {}
        text_start_index = None

        for i, line in enumerate(edited_lines):
            if line.strip() == '':
                text_start_index = i + 1
                break
            elif ':' in line:
                key, value = line.split(':', 1)
                edited_tiddler[key.strip()] = value.strip()
            else:
                text_start_index = i
                break

        if text_start_index is not None and text_start_index < len(edited_lines):
            text_content = '\n'.join(edited_lines[text_start_index:])
            if text_content:
                text_stripped = text_content.rstrip('\n')
                if text_stripped:
                    edited_tiddler['text'] = text_stripped

        # Compare the editable fields
        edited_editable = get_editable_fields(edited_tiddler)
        content_changed = (edited_editable != original_editable)

        # Check if tiddler was missing timestamps before editing
        missing_timestamps = is_new_tiddler or initial_missing_timestamps

        # Save if: content changed, new tiddler, or missing timestamps
        if is_new_tiddler or content_changed or missing_timestamps:
            # For new tiddlers, always update modified. For existing tiddlers, only update if changed.
            should_update_modified = is_new_tiddler or content_changed or initial_missing_timestamps

            # Ensure timestamps exist for both new and existing tiddlers
            if 'created' not in tiddler:
                tiddler['created'] = get_tiddlywiki_timestamp()
            if 'modified' not in tiddler:
                tiddler['modified'] = get_tiddlywiki_timestamp()

            # Add timestamps to edited_content before saving
            edited_content_lines = edited_content.split('\n')
            # Find where to insert timestamps (before the empty line or text)
            insert_pos = 0
            for i, line in enumerate(edited_content_lines):
                if line.strip() == '':
                    insert_pos = i
                    break

            # Reconstruct content with timestamps
            new_lines = edited_content_lines[:insert_pos]
            # Always add created timestamp
            new_lines.insert(insert_pos, f"created: {tiddler['created']}")
            # Only add modified if content didn't change (otherwise replace_tiddler will update it)
            if not content_changed:
                new_lines.insert(insert_pos + 1, f"modified: {tiddler['modified']}")
            new_lines.extend(edited_content_lines[insert_pos:])
            edited_content = '\n'.join(new_lines)

            # Use replace_tiddler to save the changes (final save when editor closes)
            replace_tiddler(wiki_path, edited_content, update_modified=should_update_modified)

    finally:
        # Clean up the temporary file
        try:
            os.unlink(temp_path)
        except OSError:
            pass

def get_tiddlywiki_timestamp():
    """Generate a TiddlyWiki timestamp in format YYYYMMDDhhmmssxxx (UTC)"""
    from datetime import datetime, timezone

    now = datetime.now(timezone.utc)
    # Format: YYYYMMDDhhmmssxxx where xxx is milliseconds
    timestamp = now.strftime('%Y%m%d%H%M%S') + f'{now.microsecond // 1000:03d}'
    return timestamp

def ensure_timestamps(tiddler, is_modification=True):
    """Ensure a tiddler has created and modified timestamps.

    Args:
        tiddler: The tiddler dict to update
        is_modification: If True, update modified timestamp. If False, only ensure created exists.

    Returns:
        The timestamp used (for consistency across the tiddler)
    """
    timestamp = get_tiddlywiki_timestamp()

    # Always ensure created exists
    if 'created' not in tiddler:
        tiddler['created'] = timestamp

    # Update modified if this is a modification
    if is_modification:
        tiddler['modified'] = timestamp

    return timestamp

def get_tiddler_field(wiki_path, tiddler_title, field_name):
    """Get the value of a specific field from a tiddler"""
    # Use early-exit optimization to stop parsing after finding target
    all_tiddlers = load_all_tiddlers(wiki_path, target_title=tiddler_title)

    # Find the tiddler with matching title
    tiddler = None
    for t in all_tiddlers:
        if t.get('title') == tiddler_title:
            tiddler = t
            break

    if not tiddler:
        print(f"Error: Tiddler '{tiddler_title}' not found", file=sys.stderr)
        sys.exit(1)

    if field_name not in tiddler:
        print(f"Error: Field '{field_name}' not found in tiddler '{tiddler_title}'", file=sys.stderr)
        sys.exit(1)

    # Print the field value
    print(tiddler[field_name])

def json_tiddler(wiki_path, *tiddler_titles, export_all=False):
    """Output tiddler(s) as JSON.

    If one tiddler is specified, outputs a JSON object.
    If multiple tiddlers are specified, outputs a JSON array.
    If export_all is True, exports all tiddlers as a JSON array.
    """
    import json

    # Handle --all flag
    if export_all:
        all_tiddlers = load_all_tiddlers(wiki_path)
        # Export all tiddlers as compact JSON array (no indentation for speed)
        print(json.dumps(all_tiddlers, ensure_ascii=False))
        return

    if not tiddler_titles:
        print("Error: At least one tiddler title is required", file=sys.stderr)
        sys.exit(1)

    all_tiddlers = load_all_tiddlers(wiki_path)

    # Find all requested tiddlers
    found_tiddlers = []
    for title in tiddler_titles:
        tiddler = None
        for t in all_tiddlers:
            if t.get('title') == title:
                tiddler = t
                break

        if not tiddler:
            print(f"Error: Tiddler '{title}' not found", file=sys.stderr)
            sys.exit(1)

        found_tiddlers.append(tiddler)

    # Output format depends on number of tiddlers
    if len(found_tiddlers) == 1:
        # Single tiddler - output as object (backward compatible)
        print(json.dumps(found_tiddlers[0], indent=2, ensure_ascii=False))
    else:
        # Multiple tiddlers - output as array
        print(json.dumps(found_tiddlers, indent=2, ensure_ascii=False))

def set_tiddler_field(wiki_path, tiddler_title, field_name, field_value):
    """Set the value of a specific field in a tiddler. Works with both modern and legacy formats."""
    import json

    ensure_local_wiki(wiki_path)

    with open(wiki_path, 'r', encoding='utf-8') as f:
        content = f.read()

    wiki_format = detect_wiki_format(content)

    if wiki_format == 'modern':
        # Use early-exit optimization to stop parsing after finding target
        stores = extract_tiddler_stores(content, target_title=tiddler_title)
        if not stores:
            print("Error: Could not find any tiddler stores in wiki", file=sys.stderr)
            sys.exit(1)

        # Find the tiddler in any store
        found_tiddler = None
        for store in stores:
            for tiddler in store['tiddlers']:
                if tiddler.get('title') == tiddler_title:
                    found_tiddler = tiddler
                    break
            if found_tiddler:
                break

        is_new_tiddler = False
        if not found_tiddler:
            # Create new tiddler if it doesn't exist
            found_tiddler = {
                "title": tiddler_title
            }
            is_new_tiddler = True
            # Add to the first store
            stores[0]['tiddlers'].append(found_tiddler)
            verbose_print(f"Created tiddler: {tiddler_title}")

        # Check if the field value actually changed
        old_value = found_tiddler.get(field_name)
        field_changed = (old_value != field_value)

        # Set the field value
        found_tiddler[field_name] = field_value

        # Update timestamps if:
        # 1. This is a new tiddler, OR
        # 2. The field changed AND we're not setting timestamps directly
        if is_new_tiddler or (field_changed and field_name not in ('modified', 'created')):
            ensure_timestamps(found_tiddler, is_modification=True)
        elif not is_new_tiddler:
            # For existing tiddlers, ensure created exists even if nothing changed
            ensure_timestamps(found_tiddler, is_modification=False)

        # Build replacements for all stores
        replacements = []
        for store in stores:
            sorted_tiddlers = sorted(store['tiddlers'], key=lambda t: t.get('title', ''))
            tiddler_jsons = [json.dumps(reorder_tiddler_fields(t, wiki_path, t.get('title', '')), ensure_ascii=False, separators=(',', ':')) for t in sorted_tiddlers]
            new_json = '[\n' + ',\n'.join(tiddler_jsons) + '\n]'
            new_json = new_json.replace('<', '\\u003C')
            new_store = f'<script class="tiddlywiki-tiddler-store" type="application/json">{new_json}</script>'
            replacements.append((store['start'], store['end'], new_store))

        new_content = content
        for start, end, replacement in reversed(replacements):
            new_content = new_content[:start] + replacement + new_content[end:]

        with open(wiki_path, 'w', encoding='utf-8') as f:
            f.write(new_content)

    elif wiki_format == 'legacy':
        # Load all tiddlers
        all_tiddlers = load_all_tiddlers(wiki_path)

        # Find the tiddler
        found_tiddler = None
        for tiddler in all_tiddlers:
            if tiddler.get('title') == tiddler_title:
                found_tiddler = tiddler
                break

        is_new_tiddler = False
        if not found_tiddler:
            # Create new tiddler if it doesn't exist
            found_tiddler = {
                "title": tiddler_title
            }
            is_new_tiddler = True
            all_tiddlers.append(found_tiddler)
            verbose_print(f"Created tiddler: {tiddler_title}")

        # Check if the field value actually changed
        old_value = found_tiddler.get(field_name)
        field_changed = (old_value != field_value)

        # Set the field value
        found_tiddler[field_name] = field_value

        # Update timestamps
        if is_new_tiddler or (field_changed and field_name not in ('modified', 'created')):
            ensure_timestamps(found_tiddler, is_modification=True)
        elif not is_new_tiddler:
            ensure_timestamps(found_tiddler, is_modification=False)

        write_legacy_wiki(wiki_path, all_tiddlers)

    verbose_print(f"Set {field_name} = {field_value}")

def touch_tiddler(wiki_path, tiddler_title, text=""):
    """Create a new tiddler or update an existing one. Works with both modern and legacy formats."""
    import json

    ensure_local_wiki(wiki_path)

    with open(wiki_path, 'r', encoding='utf-8') as f:
        content = f.read()

    wiki_format = detect_wiki_format(content)

    if wiki_format == 'modern':
        stores = extract_tiddler_stores(content)
        if not stores:
            print("Error: Could not find any tiddler stores in wiki", file=sys.stderr)
            sys.exit(1)

        # Check if tiddler already exists
        existing_tiddler = None
        for store in stores:
            for tiddler in store['tiddlers']:
                if tiddler.get('title') == tiddler_title:
                    existing_tiddler = tiddler
                    break
            if existing_tiddler:
                break

        if existing_tiddler:
            # Update existing tiddler's modified timestamp and ensure created exists
            ensure_timestamps(existing_tiddler, is_modification=True)
            if text:
                existing_tiddler['text'] = text
            verbose_print(f"Updated tiddler: {tiddler_title}")
        else:
            # Create new tiddler
            new_tiddler = {
                "title": tiddler_title,
                "text": text
            }
            ensure_timestamps(new_tiddler, is_modification=True)

            # Add to the first store
            stores[0]['tiddlers'].append(new_tiddler)
            verbose_print(f"Created tiddler: {tiddler_title}")

        # Build replacements for all stores
        replacements = []
        for store in stores:
            sorted_tiddlers = sorted(store['tiddlers'], key=lambda t: t.get('title', ''))
            tiddler_jsons = [json.dumps(reorder_tiddler_fields(t, wiki_path, t.get('title', '')), ensure_ascii=False, separators=(',', ':')) for t in sorted_tiddlers]
            new_json = '[\n' + ',\n'.join(tiddler_jsons) + '\n]'
            new_json = new_json.replace('<', '\\u003C')
            new_store = f'<script class="tiddlywiki-tiddler-store" type="application/json">{new_json}</script>'
            replacements.append((store['start'], store['end'], new_store))

        new_content = content
        for start, end, replacement in reversed(replacements):
            new_content = new_content[:start] + replacement + new_content[end:]

        with open(wiki_path, 'w', encoding='utf-8') as f:
            f.write(new_content)

    elif wiki_format == 'legacy':
        # Load all tiddlers
        all_tiddlers = load_all_tiddlers(wiki_path)

        # Check if tiddler already exists
        existing_tiddler = None
        for tiddler in all_tiddlers:
            if tiddler.get('title') == tiddler_title:
                existing_tiddler = tiddler
                break

        if existing_tiddler:
            # Update existing tiddler's modified timestamp and ensure created exists
            ensure_timestamps(existing_tiddler, is_modification=True)
            if text:
                existing_tiddler['text'] = text
            verbose_print(f"Updated tiddler: {tiddler_title}")
        else:
            # Create new tiddler
            new_tiddler = {
                "title": tiddler_title,
                "text": text
            }
            ensure_timestamps(new_tiddler, is_modification=True)
            all_tiddlers.append(new_tiddler)
            verbose_print(f"Created tiddler: {tiddler_title}")

        write_legacy_wiki(wiki_path, all_tiddlers)

def remove_tiddler(wiki_path, tiddler_title):
    """Remove a tiddler from the wiki. Works with both modern and legacy formats."""
    import json

    ensure_local_wiki(wiki_path)

    with open(wiki_path, 'r', encoding='utf-8') as f:
        content = f.read()

    wiki_format = detect_wiki_format(content)

    if wiki_format == 'modern':
        stores = extract_tiddler_stores(content)
        if not stores:
            print("Error: Could not find any tiddler stores in wiki", file=sys.stderr)
            sys.exit(1)

        found = False

        # Build list of replacements, removing from each store
        replacements = []
        for store in stores:
            original_count = len(store['tiddlers'])
            # Filter out the tiddler with matching title
            filtered_tiddlers = [t for t in store['tiddlers'] if t.get('title') != tiddler_title]

            if len(filtered_tiddlers) < original_count:
                found = True

            # Sort tiddlers alphabetically by title
            sorted_tiddlers = sorted(filtered_tiddlers, key=lambda t: t.get('title', ''))

            # Rebuild the script tag with filtered tiddlers
            tiddler_jsons = [json.dumps(reorder_tiddler_fields(t, wiki_path, t.get('title', '')), ensure_ascii=False, separators=(',', ':')) for t in sorted_tiddlers]
            new_json = '[\n' + ',\n'.join(tiddler_jsons) + '\n]'
            new_json = new_json.replace('<', '\\u003C')
            new_store = f'<script class="tiddlywiki-tiddler-store" type="application/json">{new_json}</script>'
            replacements.append((store['start'], store['end'], new_store))

        if not found:
            print(f"Error: Tiddler '{tiddler_title}' not found", file=sys.stderr)
            sys.exit(1)

        # Apply replacements in reverse order
        new_content = content
        for start, end, replacement in reversed(replacements):
            new_content = new_content[:start] + replacement + new_content[end:]

        # Write back
        with open(wiki_path, 'w', encoding='utf-8') as f:
            f.write(new_content)

    elif wiki_format == 'legacy':
        # Load all tiddlers
        all_tiddlers = load_all_tiddlers(wiki_path)

        # Filter out the tiddler to remove
        original_count = len(all_tiddlers)
        filtered_tiddlers = [t for t in all_tiddlers if t.get('title') != tiddler_title]

        if len(filtered_tiddlers) == original_count:
            print(f"Error: Tiddler '{tiddler_title}' not found", file=sys.stderr)
            sys.exit(1)

        write_legacy_wiki(wiki_path, filtered_tiddlers)

    verbose_print(f"Removed tiddler: {tiddler_title}")

def parse_replace_content(markdown_content, update_modified=True):
    """Parse cat-style content into a tiddler dict and normalize timestamps."""
    # Parse YAML frontmatter and text
    lines = markdown_content.split('\n')

    # Check if content is empty
    if not lines:
        print("Error: Empty content provided", file=sys.stderr)
        sys.exit(1)

    # Parse YAML-style frontmatter (key: value format)
    # Until we hit an empty line, then everything else is text
    tiddler = {}
    text_start_index = None
    user_provided_modified = False

    for i, line in enumerate(lines):
        if line.strip() == '':
            # Empty line marks end of frontmatter
            text_start_index = i + 1
            break
        elif ':' in line:
            # Parse field: value
            key, value = line.split(':', 1)
            key_stripped = key.strip()
            if key_stripped == 'modified':
                user_provided_modified = True
            tiddler[key_stripped] = value.strip()
        else:
            # If we encounter a line without ':', treat as start of text
            text_start_index = i
            break

    # Everything after the empty line (or non-field line) is the text
    if text_start_index is not None and text_start_index < len(lines):
        text_content = '\n'.join(lines[text_start_index:])
        # Strip trailing newline for perfect roundtrip with cat
        if text_content:
            # Only strip if it's just whitespace, otherwise keep the content
            text_stripped = text_content.rstrip('\n')
            if text_stripped:  # Only add text field if there's content
                tiddler['text'] = text_stripped

    # Verify it has a title field
    if 'title' not in tiddler:
        print("Error: Tiddler must have a 'title' field", file=sys.stderr)
        sys.exit(1)

    # Ensure created timestamp exists
    if 'created' not in tiddler:
        tiddler['created'] = get_tiddlywiki_timestamp()

    # Handle modified timestamp
    if 'modified' not in tiddler:
        # No modified field provided - add one
        tiddler['modified'] = get_tiddlywiki_timestamp()
    elif update_modified and not user_provided_modified:
        # Update modified timestamp only if:
        # 1. update_modified=True (requested), AND
        # 2. The user didn't explicitly provide the modified field in the input
        tiddler['modified'] = get_tiddlywiki_timestamp()

    return tiddler

def replace_tiddler(wiki_path, markdown_content, update_modified=True):
    """Replace a tiddler from cat-style format (YAML frontmatter + text)

    This is the inverse of cat_tiddler - it parses the same format that
    cat outputs and inserts it back into the wiki.

    Args:
        wiki_path: Path to the wiki file
        markdown_content: Content in cat format (YAML frontmatter + text)
        update_modified: If True, update the modified timestamp. If False, preserve existing timestamp.
    """
    import json

    ensure_local_wiki(wiki_path)

    tiddler = parse_replace_content(markdown_content, update_modified=update_modified)

    # Use insert_tiddler to do the actual insertion
    tiddler_json = json.dumps(tiddler)
    insert_tiddler(wiki_path, tiddler_json)

def append_tiddler(wiki_path, tiddler_title, text_to_append=None):
    """Append text to a tiddler's text field

    Args:
        wiki_path: Path to the wiki file
        tiddler_title: Title of the tiddler to append to
        text_to_append: Text to append (if None, read from stdin)
    """
    import json

    ensure_local_wiki(wiki_path)

    # Read from stdin if no text provided
    if text_to_append is None:
        text_to_append = sys.stdin.read()

    all_tiddlers = load_all_tiddlers(wiki_path)

    # Find the tiddler with matching title
    tiddler = None
    for t in all_tiddlers:
        if t.get('title') == tiddler_title:
            tiddler = t
            break

    if not tiddler:
        # Create new tiddler if it doesn't exist
        tiddler = {
            "title": tiddler_title,
            "text": text_to_append
        }
        # This is a new tiddler, so use is_modification=False to set both created and modified
        ensure_timestamps(tiddler, is_modification=True)
        verbose_print(f"Created tiddler: {tiddler_title}")
    else:
        # Append to existing text
        existing_text = tiddler.get('text', '')
        if existing_text:
            # Add newline between existing and new content if both have content
            tiddler['text'] = existing_text + '\n' + text_to_append
        else:
            tiddler['text'] = text_to_append

        # Update modified timestamp and ensure created exists
        ensure_timestamps(tiddler, is_modification=True)

    # Use insert_tiddler to save (it handles the full update)
    tiddler_json = json.dumps(tiddler)
    insert_tiddler(wiki_path, tiddler_json)

def serialize_legacy_tiddler(tiddler):
    """Convert a tiddler dictionary to legacy div format.

    Args:
        tiddler: Dictionary with tiddler fields

    Returns:
        HTML string representing the tiddler as a div
    """
    import html

    # Standard attribute order for consistency
    attr_order = ['created', 'creator', 'modified', 'modifier', 'revision', 'tags', 'title']

    # Build attributes string
    attrs = []
    for attr_name in attr_order:
        if attr_name in tiddler:
            attr_value = str(tiddler[attr_name])
            # Escape HTML entities in attribute values
            attr_value = html.escape(attr_value, quote=True)
            attrs.append(f'{attr_name}="{attr_value}"')

    # Add any other attributes not in the standard order
    for attr_name, attr_value in tiddler.items():
        if attr_name not in attr_order and attr_name != 'text':
            attr_value = html.escape(str(attr_value), quote=True)
            attrs.append(f'{attr_name}="{attr_value}"')

    attrs_str = ' '.join(attrs)

    # Build the div
    div_parts = [f'<div {attrs_str}>']

    # Add text content wrapped in <pre> tag if present
    if 'text' in tiddler:
        text_content = tiddler['text']
        # Escape HTML entities in text
        text_content = html.escape(text_content, quote=False)
        div_parts.append(f'<pre>{text_content}</pre>')

    div_parts.append('</div>')

    return '\n'.join(div_parts)

def build_legacy_store(tiddlers):
    """Build a complete legacy storeArea from a list of tiddlers.

    Args:
        tiddlers: List of tiddler dictionaries

    Returns:
        HTML string with <div id="storeArea"> containing all tiddlers
    """
    # Sort tiddlers by title
    sorted_tiddlers = sorted(tiddlers, key=lambda t: t.get('title', ''))

    store_parts = ['<div id="storeArea" style="display:none;">']

    for tiddler in sorted_tiddlers:
        tiddler_html = serialize_legacy_tiddler(tiddler)
        store_parts.append(tiddler_html)

    store_parts.append('</div>')

    return '\n'.join(store_parts)

def write_legacy_wiki(wiki_path, tiddlers):
    """Write tiddlers back to a legacy format wiki.

    Args:
        wiki_path: Path to the wiki file
        tiddlers: List of tiddler dictionaries to write
    """
    import re

    ensure_local_wiki(wiki_path)

    with open(wiki_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # Find the storeArea location
    store_pattern = r'<div id="storeArea"[^>]*>'
    store_match = re.search(store_pattern, content)
    if not store_match:
        print("Error: Could not find storeArea in wiki", file=sys.stderr)
        sys.exit(1)

    store_start = store_match.start()

    # Find the closing </div> for storeArea
    div_open_pattern = re.compile(r'<div(?:\s+[^>]*)?>|</div>', re.DOTALL)
    div_count = 1
    store_end = None

    for match in div_open_pattern.finditer(content, store_match.end()):
        tag = match.group()
        if tag.startswith('</'):
            div_count -= 1
            if div_count == 0:
                store_end = match.end()
                break
        else:
            div_count += 1

    if store_end is None:
        print("Error: Could not find closing tag for storeArea", file=sys.stderr)
        sys.exit(1)

    # Build new store area
    new_store = build_legacy_store(tiddlers)

    # Replace the old store with the new one
    new_content = content[:store_start] + new_store + content[store_end:]

    # Write back
    with open(wiki_path, 'w', encoding='utf-8') as f:
        f.write(new_content)

def insert_tiddler(wiki_path, tiddler_json):
    """Insert tiddler(s) from JSON, replacing if they already exist.

    Accepts either a single tiddler as a JSON object or multiple tiddlers as a JSON array.
    Works with both modern and legacy wiki formats.
    """
    import json

    ensure_local_wiki(wiki_path)

    # Parse the input JSON
    try:
        parsed_json = json.loads(tiddler_json)
    except json.JSONDecodeError as e:
        print(f"Error: Invalid JSON: {e}", file=sys.stderr)
        sys.exit(1)

    # Determine if we have a single tiddler (dict) or multiple tiddlers (list)
    if isinstance(parsed_json, dict):
        # Single tiddler - use existing logic
        tiddlers_to_insert = [parsed_json]
    elif isinstance(parsed_json, list):
        # Multiple tiddlers
        tiddlers_to_insert = parsed_json
    else:
        print("Error: JSON must be either an object (single tiddler) or an array (multiple tiddlers)", file=sys.stderr)
        sys.exit(1)

    # Validate all tiddlers before inserting any
    for i, tiddler in enumerate(tiddlers_to_insert):
        if not isinstance(tiddler, dict):
            print(f"Error: Array element {i} is not a valid tiddler object", file=sys.stderr)
            sys.exit(1)
        if 'title' not in tiddler:
            print(f"Error: Array element {i} is missing required 'title' field", file=sys.stderr)
            sys.exit(1)

    # Load the wiki and detect format
    with open(wiki_path, 'r', encoding='utf-8') as f:
        content = f.read()

    wiki_format = detect_wiki_format(content)

    # Track which tiddlers were replaced vs inserted
    replaced_titles = []
    inserted_titles = []

    if wiki_format == 'modern':
        # Use modern format - maintain separate stores
        stores = extract_tiddler_stores(content)
        if not stores:
            print("Error: Could not find any tiddler stores in wiki", file=sys.stderr)
            sys.exit(1)

        # Process each tiddler to insert
        for new_tiddler in tiddlers_to_insert:
            # Ensure timestamps exist
            if 'created' not in new_tiddler:
                new_tiddler['created'] = get_tiddlywiki_timestamp()
            if 'modified' not in new_tiddler:
                new_tiddler['modified'] = get_tiddlywiki_timestamp()

            tiddler_title = new_tiddler['title']

            # Check if tiddler already exists in any store and remove it
            found = False
            for store in stores:
                original_count = len(store['tiddlers'])
                store['tiddlers'] = [t for t in store['tiddlers'] if t.get('title') != tiddler_title]
                if len(store['tiddlers']) < original_count:
                    found = True

            # Add the new tiddler to the first store
            stores[0]['tiddlers'].append(new_tiddler)

            # Track what happened
            if found:
                replaced_titles.append(tiddler_title)
            else:
                inserted_titles.append(tiddler_title)

        # Build replacements for all stores
        replacements = []
        for store in stores:
            sorted_tiddlers = sorted(store['tiddlers'], key=lambda t: t.get('title', ''))
            tiddler_jsons = [json.dumps(reorder_tiddler_fields(t, wiki_path, t.get('title', '')), ensure_ascii=False, separators=(',', ':')) for t in sorted_tiddlers]
            new_json = '[\n' + ',\n'.join(tiddler_jsons) + '\n]'
            new_json = new_json.replace('<', '\\u003C')
            new_store = f'<script class="tiddlywiki-tiddler-store" type="application/json">{new_json}</script>'
            replacements.append((store['start'], store['end'], new_store))

        # Apply replacements in reverse order
        new_content = content
        for start, end, replacement in reversed(replacements):
            new_content = new_content[:start] + replacement + new_content[end:]

        # Write back
        with open(wiki_path, 'w', encoding='utf-8') as f:
            f.write(new_content)

    elif wiki_format == 'legacy':
        # Load all existing tiddlers
        all_tiddlers = load_all_tiddlers(wiki_path)

        # Process each tiddler to insert
        for new_tiddler in tiddlers_to_insert:
            # Ensure timestamps exist
            if 'created' not in new_tiddler:
                new_tiddler['created'] = get_tiddlywiki_timestamp()
            if 'modified' not in new_tiddler:
                new_tiddler['modified'] = get_tiddlywiki_timestamp()

            tiddler_title = new_tiddler['title']

            # Check if tiddler already exists
            found = False
            for i, existing in enumerate(all_tiddlers):
                if existing.get('title') == tiddler_title:
                    all_tiddlers[i] = new_tiddler
                    found = True
                    break

            if not found:
                all_tiddlers.append(new_tiddler)

            # Track what happened
            if found:
                replaced_titles.append(tiddler_title)
            else:
                inserted_titles.append(tiddler_title)

        # Use legacy format writing
        write_legacy_wiki(wiki_path, all_tiddlers)

    # Print summary
    for title in replaced_titles:
        verbose_print(f"Replaced tiddler: {title}")
    for title in inserted_titles:
        verbose_print(f"Inserted tiddler: {title}")

def _b64_encode_utf8(text):
    return base64.b64encode(text.encode('utf-8')).decode('ascii')

def _b64_decode_utf8(value, label):
    try:
        return base64.b64decode(value.encode('ascii')).decode('utf-8')
    except Exception as e:
        print(f"Error: Invalid base64 payload for {label}: {e}", file=sys.stderr)
        sys.exit(1)

def _coerce_text_for_markdown_export(text, mime_type):
    """Return a markdown-friendly representation of text while preserving original payload separately."""
    if not text:
        return ''

    markdown_like_types = {
        'text/markdown',
        'text/x-markdown',
        'text/plain',
        'text/vnd.tiddlywiki',
        'text/x-tiddlywiki',
        'text/vnd.tiddlywiki-multiple',
    }
    if mime_type in markdown_like_types:
        return text

    language = MIME_TO_VIM_FILETYPE.get(mime_type, 'text')
    return f"```{language}\n{text}\n```"

def is_system_tiddler_title(title):
    return isinstance(title, str) and title.startswith('$:/')

def export_filename_for_title(title):
    """Generate a human-readable export filename for a tiddler title."""
    encoded = encode_tiddler_title_for_path(title)
    # Keep export files readable while retaining URL-encoding for other characters.
    encoded = encoded.replace('%20', ' ')
    return encoded + '.md'

def build_export_markdown_document(tiddler, coerce_markdown=False):
    """Build a lossless markdown interchange document for a tiddler."""
    import json

    fields_without_text = OrderedDict((k, v) for k, v in tiddler.items() if k != 'text')
    fields_json = json.dumps(fields_without_text, ensure_ascii=False, separators=(',', ':'))

    has_text = 'text' in tiddler
    original_text = tiddler.get('text', '') if has_text else ''
    original_type = tiddler.get('type', 'text/vnd.tiddlywiki')

    body_mode = 'coerced' if coerce_markdown else 'raw'
    if coerce_markdown and has_text:
        body = _coerce_text_for_markdown_export(original_text, original_type)
    elif has_text:
        body = original_text
    else:
        body = ''

    frontmatter_lines = [
        'tw_export_version: 1',
        f'tw_body_mode: {body_mode}',
        f'tw_has_text: {1 if has_text else 0}',
        f'tw_fields_json_b64: {_b64_encode_utf8(fields_json)}',
    ]

    if coerce_markdown:
        frontmatter_lines.append(f'tw_original_type: {original_type}')
        if has_text:
            frontmatter_lines.append(f'tw_original_text_b64: {_b64_encode_utf8(original_text)}')

    return '---\n' + '\n'.join(frontmatter_lines) + '\n---\n' + body

def parse_export_markdown_document(content, file_path):
    """Parse a markdown interchange document back into a tiddler dict."""
    import json

    if not content.startswith('---\n'):
        print(f"Error: Invalid export file (missing frontmatter start): {file_path}", file=sys.stderr)
        sys.exit(1)

    frontmatter_end = content.find('\n---\n', 4)
    if frontmatter_end == -1:
        print(f"Error: Invalid export file (missing frontmatter end): {file_path}", file=sys.stderr)
        sys.exit(1)

    frontmatter_text = content[4:frontmatter_end]
    body = content[frontmatter_end + 5:]

    frontmatter = {}
    for line in frontmatter_text.split('\n'):
        if not line.strip():
            continue
        if ':' not in line:
            print(f"Error: Invalid frontmatter line in {file_path}: {line}", file=sys.stderr)
            sys.exit(1)
        key, value = line.split(':', 1)
        frontmatter[key.strip()] = value.strip()

    required_keys = ['tw_export_version', 'tw_body_mode', 'tw_has_text', 'tw_fields_json_b64']
    for key in required_keys:
        if key not in frontmatter:
            print(f"Error: Missing required frontmatter key '{key}' in {file_path}", file=sys.stderr)
            sys.exit(1)

    if frontmatter['tw_export_version'] != '1':
        print(f"Error: Unsupported export version '{frontmatter['tw_export_version']}' in {file_path}", file=sys.stderr)
        sys.exit(1)

    body_mode = frontmatter['tw_body_mode']
    if body_mode not in ('raw', 'coerced'):
        print(f"Error: Invalid tw_body_mode '{body_mode}' in {file_path}", file=sys.stderr)
        sys.exit(1)

    has_text_raw = frontmatter['tw_has_text'].lower()
    if has_text_raw in ('1', 'true', 'yes'):
        has_text = True
    elif has_text_raw in ('0', 'false', 'no'):
        has_text = False
    else:
        print(f"Error: Invalid tw_has_text value '{frontmatter['tw_has_text']}' in {file_path}", file=sys.stderr)
        sys.exit(1)

    fields_json = _b64_decode_utf8(frontmatter['tw_fields_json_b64'], f"tw_fields_json_b64 in {file_path}")
    try:
        parsed_fields = json.loads(fields_json)
    except json.JSONDecodeError as e:
        print(f"Error: Invalid decoded field JSON in {file_path}: {e}", file=sys.stderr)
        sys.exit(1)

    if not isinstance(parsed_fields, dict):
        print(f"Error: Decoded fields must be an object in {file_path}", file=sys.stderr)
        sys.exit(1)

    tiddler = OrderedDict(parsed_fields)
    if 'title' not in tiddler:
        print(f"Error: Imported file is missing title field in {file_path}", file=sys.stderr)
        sys.exit(1)

    if has_text:
        if body_mode == 'coerced':
            if 'tw_original_text_b64' not in frontmatter:
                print(f"Error: Missing tw_original_text_b64 in coerced file {file_path}", file=sys.stderr)
                sys.exit(1)
            tiddler['text'] = _b64_decode_utf8(frontmatter['tw_original_text_b64'], f"tw_original_text_b64 in {file_path}")
            if 'tw_original_type' in frontmatter and frontmatter['tw_original_type']:
                tiddler['type'] = frontmatter['tw_original_type']
        else:
            tiddler['text'] = body
    else:
        tiddler.pop('text', None)

    return tiddler

def export_tiddlers_to_dir(
    wiki_path,
    dest_dir,
    filter_expr=None,
    coerce_markdown=False,
    force=False,
    include_system=False,
):
    """Export wiki tiddlers to a directory of markdown files."""
    all_tiddlers = load_all_tiddlers(wiki_path)

    if filter_expr:
        filtered_titles = tw_filter.evaluate_filter(filter_expr, wiki_path=wiki_path)
        title_to_tiddler = {}
        for tiddler in all_tiddlers:
            title = tiddler.get('title')
            if title and title not in title_to_tiddler:
                title_to_tiddler[title] = tiddler

        selected = []
        seen = set()
        for title in filtered_titles:
            if title in seen:
                continue
            seen.add(title)
            if title in title_to_tiddler:
                selected.append(title_to_tiddler[title])
    else:
        selected = sorted(all_tiddlers, key=lambda t: t.get('title', ''))

    if not include_system:
        selected = [t for t in selected if not is_system_tiddler_title(t.get('title'))]

    if os.path.exists(dest_dir) and not os.path.isdir(dest_dir):
        print(f"Error: Destination path is not a directory: {dest_dir}", file=sys.stderr)
        sys.exit(1)
    os.makedirs(dest_dir, exist_ok=True)

    files_to_write = []
    seen_paths = set()
    for tiddler in selected:
        title = tiddler.get('title')
        if not title:
            continue
        filename = export_filename_for_title(title)
        path = os.path.join(dest_dir, filename)
        if path in seen_paths:
            print(f"Error: Export filename collision for title '{title}'", file=sys.stderr)
            sys.exit(1)
        seen_paths.add(path)
        files_to_write.append((path, tiddler))

    if not force:
        for path, _ in files_to_write:
            if os.path.exists(path):
                print(f"Error: File already exists (use --force to overwrite): {path}", file=sys.stderr)
                sys.exit(1)

    for path, tiddler in files_to_write:
        content = build_export_markdown_document(tiddler, coerce_markdown=coerce_markdown)
        temp_path = path + '.tmp'
        try:
            with open(temp_path, 'w', encoding='utf-8') as f:
                f.write(content)
            os.replace(temp_path, path)
        except Exception as e:
            if os.path.exists(temp_path):
                try:
                    os.remove(temp_path)
                except OSError:
                    pass
            print(f"Error: Failed to export file {path}: {e}", file=sys.stderr)
            sys.exit(1)

    verbose_print(f"Exported {len(files_to_write)} tiddler(s) to {dest_dir}")

def import_tiddlers_from_dir(wiki_path, source_dir, mode='upsert', delete_missing=False, dry_run=False):
    """Import a directory of markdown-exported tiddlers into a wiki transactionally."""
    ensure_local_wiki(wiki_path)

    if mode not in ('upsert', 'replace', 'create-only'):
        print(f"Error: Invalid import mode '{mode}'", file=sys.stderr)
        sys.exit(1)
    if mode == 'create-only' and delete_missing:
        print("Error: --delete-missing is not valid with --mode create-only", file=sys.stderr)
        sys.exit(1)

    if not os.path.isdir(source_dir):
        print(f"Error: Import source is not a directory: {source_dir}", file=sys.stderr)
        sys.exit(1)

    filenames = sorted(
        name for name in os.listdir(source_dir)
        if name.endswith('.md') and os.path.isfile(os.path.join(source_dir, name))
    )
    if not filenames:
        print(f"Error: No markdown files found in directory: {source_dir}", file=sys.stderr)
        sys.exit(1)

    imported_tiddlers = []
    imported_titles = set()

    for filename in filenames:
        path = os.path.join(source_dir, filename)
        try:
            with open(path, 'r', encoding='utf-8') as f:
                content = f.read()
        except OSError as e:
            print(f"Error: Failed to read import file {path}: {e}", file=sys.stderr)
            sys.exit(1)

        tiddler = parse_export_markdown_document(content, path)
        title = tiddler.get('title')
        if title in imported_titles:
            print(f"Error: Duplicate title '{title}' found in import directory", file=sys.stderr)
            sys.exit(1)
        imported_titles.add(title)
        imported_tiddlers.append(tiddler)

    state = load_ops_state(wiki_path)
    existing_titles = {t.get('title') for t in ops_state_all_tiddlers(state) if 'title' in t}

    create_count = len(imported_titles - existing_titles)
    update_count = len(imported_titles & existing_titles)
    delete_count = 0
    if mode == 'replace':
        delete_count = len(existing_titles - imported_titles)
    elif mode == 'upsert' and delete_missing:
        delete_count = len(existing_titles - imported_titles)

    collisions = sorted(imported_titles & existing_titles)
    if mode == 'create-only' and collisions:
        print(f"Error: create-only mode found existing titles: {', '.join(collisions[:10])}", file=sys.stderr)
        sys.exit(1)

    if dry_run:
        print(f"Dry run: create={create_count} update={update_count} delete={delete_count}")
        return

    if mode == 'replace':
        if state["wiki_format"] == 'modern':
            for store in state["stores"]:
                store['tiddlers'] = []
        else:
            state["tiddlers"] = []
        ops_state_insert_tiddlers(state, imported_tiddlers)
    elif mode == 'upsert':
        ops_state_insert_tiddlers(state, imported_tiddlers)
    else:
        # create-only already validated for collisions
        ops_state_insert_tiddlers(state, imported_tiddlers)

    if mode == 'upsert' and delete_missing:
        titles_to_delete = sorted(existing_titles - imported_titles)
        for title in titles_to_delete:
            ops_state_remove_tiddler(state, title)

    commit_ops_state(state, wiki_path)
    verbose_print(f"Imported {len(imported_tiddlers)} tiddler(s) from {source_dir}")

def install_live_reload_plugin(wiki_path):
    """Install the live reload plugin into the wiki"""
    import json

    ensure_local_wiki(wiki_path)

    # The live reload plugin code
    plugin_code = """(function(){
  "use strict";

  exports.name = "live-reload";
  exports.platforms = ["browser"];
  exports.after = ["startup"];
  exports.synchronous = true;

  exports.startup = function() {
    // Only run in browser
    if($tw.browser) {
      checkForServer();
    }
  };

  function checkForServer() {
    var meta = document.querySelector('meta[name="tw-server"]');
    if (!meta || meta.getAttribute('content') !== 'enabled') {
      console.log('[LiveReload] Not running on tw server, aborting');
      return;
    }

    console.log('[LiveReload] Detected tw server, starting live reload');
    startPolling();
    enableWebDAVSaver();
  }

  function enableWebDAVSaver() {
    // Check if server supports WebDAV via OPTIONS request
    fetch('/', {method: 'OPTIONS'})
      .then(function(response) {
        var davHeader = response.headers.get('DAV');
        if (davHeader) {
          console.log('[LiveReload] WebDAV detected (DAV: ' + davHeader + '), enabling saver');

          // TiddlyWiki's WebDAV saver is already built-in and will auto-detect WebDAV support
          // We only need to set AutoSave config if it doesn't already exist or is different
          var existingTiddler = $tw.wiki.getTiddler('$:/config/AutoSave');
          var shouldUpdate = !existingTiddler || existingTiddler.fields.text !== 'yes';

          if (shouldUpdate) {
            $tw.wiki.addTiddler(new $tw.Tiddler({
              title: '$:/config/AutoSave',
              text: 'yes'
            }));
            console.log('[LiveReload] WebDAV saver enabled - you can now save changes!');
          } else {
            console.log('[LiveReload] WebDAV saver already enabled');
          }
        } else {
          console.log('[LiveReload] WebDAV not available on server');
        }
      })
      .catch(function(error) {
        console.log('[LiveReload] Could not check for WebDAV support:', error);
      });
  }

  var lastVersion = null;
  var savedVersions = {}; // Track versions we saved: {version: timestamp}
  var VERSION_SKIP_DURATION = 10000; // Skip reloading versions we saved for 10 seconds
  var isReloading = false; // Flag to prevent marking as dirty during reload
  var isSaving = false; // Flag to track when a save is in progress

  // Hook into TiddlyWiki's save mechanism to track when we initiate a save
  if ($tw.wiki) {
    var originalAddTiddler = $tw.wiki.addTiddler;
    $tw.wiki.addTiddler = function(tiddler) {
      var result = originalAddTiddler.apply(this, arguments);
      // If this is a user-initiated change (not from our plugin reload), mark as saving
      // Ignore: reloads and temporary tiddlers
      if (!isReloading &&
          tiddler &&
          tiddler.fields &&
          tiddler.fields.title &&
          !tiddler.fields.title.startsWith('$:/temp')) {

        // Debounce: only mark as saving if we're not already saving
        if (!isSaving) {
          isSaving = true;
          console.log('[LiveReload] User change detected:', tiddler.fields.title);

          // Clear the saving flag after a short delay to capture the version after save
          setTimeout(function() {
            if (isSaving) {
              // Fetch current version and mark it as saved by us
              fetch('/_tw/version')
                .then(function(response) { return response.json(); })
                .then(function(data) {
                  savedVersions[data.version] = Date.now();
                  console.log('[LiveReload] Marked version as saved:', data.version);
                  isSaving = false;
                })
                .catch(function(error) {
                  console.error('[LiveReload] Error fetching version after save:', error);
                  isSaving = false;
                });
            }
          }, 1000); // Wait 1 second for the save to complete
        }
      }
      return result;
    };
  }

  function startPolling() {
    setInterval(function() {
      checkVersion();
      cleanupOldSavedVersions();
    }, 3000); // Poll every 3 seconds
  }

  function cleanupOldSavedVersions() {
    // Remove saved versions older than VERSION_SKIP_DURATION
    var now = Date.now();
    for (var version in savedVersions) {
      if (now - savedVersions[version] > VERSION_SKIP_DURATION) {
        delete savedVersions[version];
      }
    }
  }

  function checkVersion() {
    fetch('/_tw/version')
      .then(function(response) { return response.json(); })
      .then(function(data) {
        console.log('[LiveReload] Version check:', data.version);

        if (lastVersion === null) {
          // First check, just store the version
          lastVersion = data.version;
          console.log('[LiveReload] Initial version:', lastVersion);
          return;
        }

        if (data.version !== lastVersion) {
          // Check if this version was saved by us
          if (savedVersions[data.version]) {
            var timeSinceSave = Date.now() - savedVersions[data.version];
            console.log('[LiveReload] File changed to version we just saved (' + timeSinceSave + 'ms ago), skipping reload');
            lastVersion = data.version;
            return;
          }

          console.log('[LiveReload] File changed! Old:', lastVersion, 'New:', data.version);
          lastVersion = data.version;
          reloadTiddlers();
        }
      })
      .catch(function(error) {
        console.error('[LiveReload] Error checking version:', error);
      });
  }

  function reloadTiddlers() {
    fetch('/_tw/tiddlers')
      .then(function(response) { return response.json(); })
      .then(function(data) {
        console.log('[LiveReload] Got', data.tiddlers.length, 'tiddlers from server');

        // Set flag to prevent marking wiki as dirty during reload
        isReloading = true;

        // Get current tiddler titles (all tiddlers from the store)
        var currentTitles = $tw.wiki.getTiddlers();

        var newTitles = data.tiddlers.map(function(t) { return t.title; });

        var updateCount = 0;
        var deleteCount = 0;
        var changedTiddlers = {};

        // Update/add tiddlers
        data.tiddlers.forEach(function(tiddlerData) {
          var browserTiddler = $tw.wiki.getTiddler(tiddlerData.title);

          if (!browserTiddler) {
            // New tiddler - not in browser
            console.log('[LiveReload] Adding new tiddler:', tiddlerData.title);
            $tw.wiki.addTiddler(new $tw.Tiddler(tiddlerData));
            changedTiddlers[tiddlerData.title] = true;
            updateCount++;
          } else {
            // Compare canonical serialized representations instead of field-by-field
            // This handles all data types uniformly without special cases

            // Fields to ignore when comparing (metadata/computed fields)
            var ignoreFields = {
              'modified': true,
              'created': true,
              'revision': true,
              'bag': true
            };

            // Create normalized copies without ignored fields
            var serverNormalized = {};
            var browserNormalized = {};

            // Copy server fields (except ignored)
            for (var field in tiddlerData) {
              if (!ignoreFields[field]) {
                serverNormalized[field] = tiddlerData[field];
              }
            }

            // Copy browser fields (except ignored)
            // Convert arrays to TiddlyWiki string format to match server
            for (var field in browserTiddler.fields) {
              if (!ignoreFields[field]) {
                var value = browserTiddler.fields[field];
                // TiddlyWiki represents tags/lists as arrays in browser but strings in files
                // Use TiddlyWiki's stringifyList to convert arrays to proper format
                if (Array.isArray(value) && $tw.utils.stringifyList) {
                  browserNormalized[field] = $tw.utils.stringifyList(value);
                } else {
                  browserNormalized[field] = value;
                }
              }
            }

            // Serialize both to JSON with sorted keys for consistent comparison
            var serverJson = JSON.stringify(serverNormalized, Object.keys(serverNormalized).sort());
            var browserJson = JSON.stringify(browserNormalized, Object.keys(browserNormalized).sort());

            if (serverJson !== browserJson) {
              console.log('[DEBUG] ' + tiddlerData.title + ' content changed');
              console.log('  Server JSON: ' + serverJson.substring(0, 200));
              console.log('  Browser JSON: ' + browserJson.substring(0, 200));

              $tw.wiki.addTiddler(new $tw.Tiddler(tiddlerData));
              changedTiddlers[tiddlerData.title] = true;
              updateCount++;
            }
          }
        });

        // Delete removed tiddlers
        currentTitles.forEach(function(title) {
          if (newTitles.indexOf(title) === -1) {
            console.log('[LiveReload] Deleting tiddler:', title);
            $tw.wiki.deleteTiddler(title);
            changedTiddlers[title] = true;
            deleteCount++;
          }
        });

        // Refresh the UI if any changes were made
        if (updateCount > 0 || deleteCount > 0) {
          // Trigger a refresh of the root widget
          $tw.rootWidget.refresh(changedTiddlers);
          console.log('[LiveReload] Reload complete - updated:', updateCount, 'deleted:', deleteCount);

          // Mark the wiki as saved at current change count
          // This prevents the wiki from showing as "dirty" after a reload from server
          if ($tw.wiki.getChangeCount && $tw.syncer && $tw.syncer.wiki) {
            $tw.syncer.wiki.addTiddler(new $tw.Tiddler(
              $tw.wiki.getTiddler('$:/config/SaverStartupTime'),
              {text: '' + $tw.wiki.getChangeCount()}
            ));
            console.log('[LiveReload] Updated save marker to change count:', $tw.wiki.getChangeCount());
          }
        } else {
          console.log('[LiveReload] No changes detected');
        }

        // Clear the reloading flag after a delay to let TiddlyWiki's reactive updates settle
        setTimeout(function() {
          isReloading = false;
          console.log('[LiveReload] Reload flag cleared');
        }, 500);
      })
      .catch(function(error) {
        console.error('[LiveReload] Error reloading tiddlers:', error);
        // Clear flag even on error, with delay for consistency
        setTimeout(function() {
          isReloading = false;
        }, 500);
      });
  }
})();
"""

    # Create the plugin tiddler
    plugin_tiddler = {
        "title": "$:/plugins/phajas/live-reload",
        "type": "application/javascript",
        "module-type": "startup",
        "text": plugin_code,
        "tags": "$:/tags/StartupModule",
        "description": "Live reload functionality with WebDAV save support for tw server",
        "version": "0.8.1"
    }

    # Convert to JSON and insert
    plugin_json = json.dumps(plugin_tiddler)
    insert_tiddler(wiki_path, plugin_json)

    verbose_print("Live reload plugin installed successfully")
    verbose_print("Start the server with: tw serve")

def init_wiki(dest_path):
    """Download an empty TiddlyWiki and save it to the specified path"""
    def builtin_empty_wiki():
        return """<!DOCTYPE html>
<html>
<head><title>Empty TiddlyWiki</title></head>
<body>
<script class="tiddlywiki-tiddler-store" type="application/json">
[
{"title":"$:/SiteTitle","text":"TiddlyWiki"}
]
</script>
</body>
</html>"""

    # Expand ~ to home directory
    dest_path = os.path.expanduser(dest_path)

    # Check if file already exists
    if os.path.exists(dest_path):
        print(f"Error: File already exists: {dest_path}", file=sys.stderr)
        sys.exit(1)

    # Check if parent directory exists
    parent_dir = os.path.dirname(dest_path)
    if parent_dir and not os.path.exists(parent_dir):
        print(f"Error: Parent directory does not exist: {parent_dir}", file=sys.stderr)
        sys.exit(1)

    try:
        verbose_print("Downloading empty wiki from tiddlywiki.com...")
        url = 'https://tiddlywiki.com/empty.html'
        with urllib.request.urlopen(url, timeout=10) as response:
            wiki_content = response.read().decode('utf-8')
    except Exception as e:
        print(f"Warning: Failed to download wiki, using built-in template: {e}", file=sys.stderr)
        wiki_content = builtin_empty_wiki()

    # Verify the downloaded content has tiddler stores
    stores = extract_tiddler_stores(wiki_content)
    if not stores:
        print("Error: Downloaded wiki does not contain tiddler stores", file=sys.stderr)
        sys.exit(1)

    # Write to file atomically (temp file + rename)
    temp_path = dest_path + '.tmp'
    try:
        with open(temp_path, 'w', encoding='utf-8') as f:
            f.write(wiki_content)
        os.replace(temp_path, dest_path)
    except Exception as e:
        # Clean up temp file if it exists
        if os.path.exists(temp_path):
            try:
                os.remove(temp_path)
            except:
                pass
        print(f"Error: Failed to write wiki file: {e}", file=sys.stderr)
        sys.exit(1)

    verbose_print(f"Created wiki: {dest_path}")

def serve_wiki(wiki_path, host='localhost', port=8080, readonly=False):
    """Serve the TiddlyWiki file locally using Python's built-in HTTP server

    Args:
        wiki_path: Path to the wiki HTML file
        host: Host to bind to (default: localhost)
        port: Port to bind to (default: 8080)
        readonly: If True, disable saving via PUT requests (default: False)
    """
    from http.server import HTTPServer, BaseHTTPRequestHandler
    import threading
    import time
    import json
    import mimetypes
    ensure_local_wiki(wiki_path)

    class WikiWatcher:
        """Watch the wiki file for changes and track version"""
        def __init__(self, wiki_path):
            self.wiki_path = wiki_path
            self.current_mtime = os.path.getmtime(wiki_path)
            self.lock = threading.Lock()

        def watch(self):
            """Background thread that polls for file changes"""
            while True:
                time.sleep(0.5)
                try:
                    mtime = os.path.getmtime(self.wiki_path)
                    if mtime != self.current_mtime:
                        with self.lock:
                            self.current_mtime = mtime
                        verbose_print(f"[File changed] {self.wiki_path} (mtime: {mtime})")
                except OSError as e:
                    print(f"[Warning] Could not check file: {e}", file=sys.stderr)

        def get_version(self):
            """Get the current file modification time"""
            with self.lock:
                return self.current_mtime

    # Initialize the file watcher
    watcher = WikiWatcher(wiki_path)
    watcher_thread = threading.Thread(target=watcher.watch, daemon=True)
    watcher_thread.start()

    class WikiHandler(BaseHTTPRequestHandler):
        def send_webdav_headers(self):
            """Send WebDAV-specific headers"""
            self.send_header('DAV', '1,2')
            self.send_header('Allow', 'OPTIONS, GET, HEAD, PUT')
            self.send_header('Access-Control-Allow-Origin', '*')
            self.send_header('Access-Control-Allow-Methods', 'OPTIONS, GET, HEAD, PUT')
            self.send_header('Access-Control-Allow-Headers', 'Content-Type, X-Requested-With')

        def do_OPTIONS(self):
            """Handle OPTIONS requests for WebDAV discovery"""
            self.send_response(200)
            self.send_webdav_headers()
            self.send_header('Content-Length', '0')
            self.end_headers()

        def do_PUT(self):
            """Handle PUT requests to save the wiki file"""
            # Reject all save attempts in readonly mode
            if readonly:
                self.send_error(403, 'Server is in readonly mode')
                print(f"[WebDAV PUT] Rejected save attempt (readonly mode)", file=sys.stderr)
                return

            try:
                # Read the incoming HTML from request body
                content_length = int(self.headers.get('Content-Length', 0))
                if content_length == 0:
                    self.send_error(400, 'Empty request body')
                    return

                wiki_html = self.rfile.read(content_length)

                # Decode to string for validation
                try:
                    wiki_html_str = wiki_html.decode('utf-8')
                except UnicodeDecodeError as e:
                    self.send_error(400, f'Invalid UTF-8 encoding: {e}')
                    return

                # Validate that the HTML has tiddler stores
                stores = extract_tiddler_stores(wiki_html_str)
                if not stores:
                    self.send_error(400, 'Invalid wiki HTML: no tiddler stores found')
                    print(f"[WebDAV PUT] Rejected invalid HTML (no tiddler stores)", file=sys.stderr)
                    return

                # Write to temp file first (atomic operation)
                temp_path = wiki_path + '.tmp'
                with open(temp_path, 'wb') as f:
                    f.write(wiki_html)

                # Atomic replace
                os.replace(temp_path, wiki_path)

                verbose_print(f"[WebDAV PUT] Saved wiki file ({len(wiki_html)} bytes)")

                # Return success (204 No Content is standard for WebDAV PUT)
                self.send_response(204)
                self.send_webdav_headers()
                self.end_headers()

            except Exception as e:
                print(f"[WebDAV PUT] Error saving file: {e}", file=sys.stderr)
                self.send_error(500, f'Error saving file: {e}')

        def do_HEAD(self):
            """Handle HEAD requests - same as GET but without body"""
            # Just use do_GET, but the BaseHTTPRequestHandler will automatically
            # not send the body for HEAD requests
            self.do_GET()

        def do_GET(self):
            """Handle GET requests by serving the wiki file or API endpoints"""
            # API endpoint: version check
            if self.path == '/_tw/version':
                self.send_version_response()
                return

            # API endpoint: tiddlers JSON
            if self.path == '/_tw/tiddlers':
                self.send_tiddlers_response()
                return

            # Root path: serve the wiki HTML
            if self.path == '/' or self.path == '':
                self.send_wiki_html()
                return

            # For any other path, try to serve as a file (for _canonical_uri support)
            self.send_file()

        def send_version_response(self):
            """Send current file version/mtime"""
            try:
                version = watcher.get_version()
                response_data = {
                    "version": version,
                    "mtime": version,
                    "server": "tw-python"
                }

                response_json = json.dumps(response_data).encode('utf-8')

                self.send_response(200)
                self.send_header('Content-Type', 'application/json')
                self.send_header('Content-Length', str(len(response_json)))
                self.end_headers()
                self.wfile.write(response_json)
            except Exception as e:
                self.send_error(500, f'Error getting version: {e}')

        def send_tiddlers_response(self):
            """Send the tiddler store JSON"""
            try:
                # Load all tiddlers from the wiki
                all_tiddlers = load_all_tiddlers(wiki_path)
                version = watcher.get_version()

                response_data = {
                    "version": version,
                    "tiddlers": all_tiddlers
                }

                response_json = json.dumps(response_data, ensure_ascii=False).encode('utf-8')

                self.send_response(200)
                self.send_header('Content-Type', 'application/json')
                self.send_header('Content-Length', str(len(response_json)))
                self.end_headers()
                self.wfile.write(response_json)
            except Exception as e:
                self.send_error(500, f'Error getting tiddlers: {e}')

        def send_wiki_html(self):
            """Serve the wiki HTML with injected meta tag"""
            try:
                with open(wiki_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                # Inject meta tag after <head> or at the beginning if no head tag
                meta_tag = '<meta name="tw-server" content="enabled">'

                # Look for <head> tag (case insensitive)
                head_pos = content.lower().find('<head>')
                if head_pos != -1:
                    # Find the end of the <head> tag
                    insert_pos = content.find('>', head_pos) + 1
                    content = content[:insert_pos] + '\n' + meta_tag + content[insert_pos:]
                else:
                    # No head tag, insert at the beginning
                    content = meta_tag + '\n' + content

                content_bytes = content.encode('utf-8')

                self.send_response(200)
                self.send_header('Content-Type', 'text/html; charset=utf-8')
                self.send_header('Content-Length', str(len(content_bytes)))
                self.end_headers()
                self.wfile.write(content_bytes)
            except (ConnectionResetError, BrokenPipeError) as e:
                # Client closed connection - this is normal, just log it
                verbose_print(f"[Client disconnected] {e.__class__.__name__}")
            except Exception as e:
                try:
                    self.send_error(500, f'Error reading wiki file: {e}')
                except (ConnectionResetError, BrokenPipeError):
                    # Can't send error if connection is already broken
                    verbose_print(f"[Client disconnected during error handling]")

        def send_file(self):
            """Serve a file from the filesystem (for _canonical_uri support)"""
            try:
                # Parse the request path, removing query parameters and fragments
                from urllib.parse import urlparse, unquote
                parsed_path = urlparse(self.path)
                # Decode URL encoding (e.g., %20 -> space)
                file_path = unquote(parsed_path.path)

                # Remove leading slash
                if file_path.startswith('/'):
                    file_path = file_path[1:]

                # Prevent directory traversal attacks
                if '..' in file_path or file_path.startswith('/'):
                    self.send_error(403, 'Access denied')
                    return

                # Resolve path relative to wiki file's directory
                wiki_dir = os.path.dirname(os.path.abspath(wiki_path))
                full_path = os.path.join(wiki_dir, file_path)

                # Normalize the path to resolve any .. or . components
                full_path = os.path.normpath(full_path)

                # Ensure the resolved path is still within wiki_dir
                if not full_path.startswith(wiki_dir):
                    self.send_error(403, 'Access denied')
                    return

                # Check if file exists and is a file (not a directory)
                if not os.path.isfile(full_path):
                    self.send_error(404, 'File not found')
                    return

                # Determine MIME type
                mime_type, _ = mimetypes.guess_type(full_path)
                if mime_type is None:
                    mime_type = 'application/octet-stream'

                # Read and serve the file
                with open(full_path, 'rb') as f:
                    content = f.read()

                self.send_response(200)
                self.send_header('Content-Type', mime_type)
                self.send_header('Content-Length', str(len(content)))
                # Add CORS headers to allow cross-origin requests
                self.send_header('Access-Control-Allow-Origin', '*')
                self.end_headers()
                self.wfile.write(content)

                verbose_print(f"[File served] {file_path} ({mime_type}, {len(content)} bytes)")

            except (ConnectionResetError, BrokenPipeError) as e:
                # Client closed connection - this is normal
                verbose_print(f"[Client disconnected] {e.__class__.__name__}")
            except Exception as e:
                print(f"[Error serving file] {e}", file=sys.stderr)
                try:
                    self.send_error(500, f'Error serving file: {e}')
                except (ConnectionResetError, BrokenPipeError):
                    verbose_print(f"[Client disconnected during error handling]")

        def log_message(self, format, *args):
            """Override to provide cleaner log messages"""
            verbose_print(f"[{self.log_date_time_string()}] {format % args}")

    try:
        server = HTTPServer((host, port), WikiHandler)
        if readonly:
            verbose_print(f"Serving TiddlyWiki at http://{host}:{port} (READONLY MODE)")
        else:
            verbose_print(f"Serving TiddlyWiki at http://{host}:{port}")
        verbose_print(f"Wiki file: {wiki_path}")
        if readonly:
            verbose_print("Mode: READONLY - save attempts will be rejected")
        verbose_print("Press Ctrl+C to stop the server")
        server.serve_forever()
    except KeyboardInterrupt:
        verbose_print("\nServer stopped")
        sys.exit(0)
    except OSError as e:
        if e.errno == 48 or e.errno == 98:  # Address already in use
            print(f"Error: Port {port} is already in use", file=sys.stderr)
        else:
            print(f"Error starting server: {e}", file=sys.stderr)
        sys.exit(1)

def serve_webdav(wiki_path, host='localhost', port=8081, readonly=False):
    """Serve tiddlers over WebDAV in tw cat format.

    Args:
        wiki_path: Path to the wiki HTML file
        host: Host to bind to (default: localhost)
        port: Port to bind to (default: 8081)
        readonly: If True, disable writing via WebDAV (default: False)
    """
    from http.server import HTTPServer, BaseHTTPRequestHandler
    from datetime import datetime, timezone
    from email.utils import format_datetime
    from xml.sax.saxutils import escape
    import contextlib
    import io
    import json
    import urllib.parse
    import uuid

    ensure_local_wiki(wiki_path)

    mkcol_paths = set()
    lock_tokens = {}
    scratch_files = {}
    scratch_collection_pattern = re.compile(r'\.sb-[0-9a-f]{8}-[A-Za-z0-9]{6,}', re.IGNORECASE)

    def is_scratch_name(name):
        return name.startswith('._') or name == '.DS_Store'

    def looks_like_scratch_collection(name):
        return scratch_collection_pattern.search(name) is not None

    def scratch_collection_exists(collection_path):
        if collection_path in mkcol_paths:
            return True
        for key in scratch_files.keys():
            if key.startswith(collection_path):
                return True
        return False

    def normalize_collection_path(path):
        if not path.startswith('/'):
            path = '/' + path
        return path if path.endswith('/') else path + '/'

    def parse_timestamp(value):
        if not value:
            return None
        try:
            base = value[:14]
            return datetime.strptime(base, "%Y%m%d%H%M%S").replace(tzinfo=timezone.utc)
        except Exception:
            return None

    def format_http_date(value):
        if isinstance(value, datetime):
            dt = value
        else:
            dt = parse_timestamp(value)
        if dt is None:
            dt = datetime.now(timezone.utc)
        return format_datetime(dt, usegmt=True)

    def parse_cat_content(content):
        normalized = content.replace('\r\n', '\n').replace('\r', '\n')
        lines = normalized.split('\n')
        tiddler = {}
        text_start_index = None

        for i, line in enumerate(lines):
            if line.strip() == '':
                text_start_index = i + 1
                break
            elif ':' in line:
                key, value = line.split(':', 1)
                tiddler[key.strip()] = value.strip()
            else:
                text_start_index = i
                break

        if text_start_index is not None and text_start_index < len(lines):
            text_content = '\n'.join(lines[text_start_index:])
            if text_content:
                text_stripped = text_content.rstrip('\n')
                if text_stripped:
                    tiddler['text'] = text_stripped

        return tiddler

    class WebDavHandler(BaseHTTPRequestHandler):
        def log_message(self, format, *args):
            verbose_print(f"[{self.log_date_time_string()}] {format % args}")

        def send_webdav_headers(self):
            self.send_header('DAV', '1,2')
            self.send_header('MS-Author-Via', 'DAV')
            self.send_header('Allow', 'OPTIONS, PROPFIND, GET, HEAD, PUT, DELETE, LOCK, UNLOCK, MKCOL')
            self.send_header('Access-Control-Allow-Origin', '*')
            self.send_header('Access-Control-Allow-Methods', 'OPTIONS, PROPFIND, GET, HEAD, PUT, DELETE, LOCK, UNLOCK, MKCOL')
            self.send_header('Access-Control-Allow-Headers', 'Content-Type, Depth, X-Requested-With, Lock-Token, If, Timeout')

        def _parse_path(self):
            parsed = urllib.parse.urlparse(self.path)
            path = parsed.path or '/'
            if not path.startswith('/'):
                path = '/' + path

            if path in ('', '/'):
                return ('root', None, '/')

            collection_path = normalize_collection_path(path)
            if collection_path == '/tiddlers/':
                return ('collection', collection_path, collection_path)
            if collection_path in mkcol_paths:
                collection_name = collection_path.strip('/').split('/')[-1]
                decoded_name = decode_tiddler_title_from_path(collection_name)
                if collection_path.startswith('/tiddlers/') and looks_like_scratch_collection(decoded_name):
                    return ('scratch_collection', collection_path, '/tiddlers/')
                return ('collection', collection_path, collection_path)

            if path.startswith('/tiddlers/'):
                segment = path[len('/tiddlers/'):]
                segment = segment.rstrip('/')
                if not segment:
                    return ('collection', '/tiddlers/', '/tiddlers/')
                if '/' in segment:
                    scratch_key = '/tiddlers/' + segment
                    return ('scratch_file', scratch_key, '/tiddlers/')
                decoded_segment = decode_tiddler_title_from_path(segment)
                if looks_like_scratch_collection(decoded_segment):
                    collection_path = normalize_collection_path('/tiddlers/' + segment)
                    if scratch_collection_exists(collection_path):
                        return ('scratch_collection', collection_path, '/tiddlers/')
                if is_scratch_name(decoded_segment):
                    scratch_key = '/tiddlers/' + segment
                    return ('scratch_file', scratch_key, '/tiddlers/')
                return ('tiddler', decoded_segment, '/tiddlers/')

            segment = path[1:].rstrip('/')
            if not segment:
                return ('root', None, '/')
            return ('tiddler', decode_tiddler_title_from_path(segment), '/')

        def _href_for_title(self, title, prefix='/'):
            if not prefix.startswith('/'):
                prefix = '/' + prefix
            if not prefix.endswith('/'):
                prefix = prefix + '/'
            return prefix + encode_tiddler_title_for_path(title)

        def _load_tiddlers(self, **kwargs):
            try:
                return load_all_tiddlers(wiki_path, **kwargs)
            except SystemExit as e:
                raise RuntimeError("Failed to load wiki") from e

        def _get_tiddler(self, title):
            tiddlers = self._load_tiddlers(target_title=title)
            for tiddler in tiddlers:
                if tiddler.get('title') == title:
                    return tiddler
            return None

        def _resolve_title(self, encoded_title):
            """Resolve an encoded path segment to a tiddler title.

            Since encoding is now reversible, we just decode and check if it exists.
            If it doesn't exist, we still return the decoded value to support
            creating new tiddlers."""
            decoded = encoded_title
            titles = self._load_tiddlers(titles_only=True)

            # Check if the decoded title exists
            if decoded in titles:
                return decoded

            # If not found, return decoded value anyway (for creating new tiddlers)
            return decoded

        def _send_text(self, body, status=200, headers=None, include_body=True, last_modified=None):
            body_bytes = body.encode('utf-8')
            self.send_response(status)
            self.send_webdav_headers()
            self.send_header('Content-Type', 'text/plain; charset=utf-8')
            self.send_header('Content-Length', str(len(body_bytes)))
            if last_modified:
                self.send_header('Last-Modified', last_modified)
            if headers:
                for key, value in headers.items():
                    self.send_header(key, value)
            self.end_headers()
            if include_body:
                self.wfile.write(body_bytes)

        def _send_bytes(self, body_bytes, status=200, headers=None, include_body=True, content_type='application/octet-stream'):
            self.send_response(status)
            self.send_webdav_headers()
            self.send_header('Content-Type', content_type)
            self.send_header('Content-Length', str(len(body_bytes)))
            if headers:
                for key, value in headers.items():
                    self.send_header(key, value)
            self.end_headers()
            if include_body:
                self.wfile.write(body_bytes)

        def _send_xml(self, body, status=207):
            body_bytes = body.encode('utf-8')
            self.send_response(status)
            self.send_webdav_headers()
            self.send_header('Content-Type', 'application/xml; charset=utf-8')
            self.send_header('Content-Length', str(len(body_bytes)))
            self.end_headers()
            self.wfile.write(body_bytes)

        def _prop_response(self, href, displayname, is_collection, length=None, modified=None, content_type=None):
            props = []
            if displayname is not None:
                props.append(f"<D:displayname>{escape(displayname)}</D:displayname>")
            if is_collection:
                props.append("<D:resourcetype><D:collection/></D:resourcetype>")
            else:
                props.append("<D:resourcetype/>")
            if modified:
                props.append(f"<D:getlastmodified>{escape(modified)}</D:getlastmodified>")
            if length is not None:
                props.append(f"<D:getcontentlength>{length}</D:getcontentlength>")
            if content_type:
                props.append(f"<D:getcontenttype>{escape(content_type)}</D:getcontenttype>")

            return (
                "<D:response>"
                f"<D:href>{escape(href)}</D:href>"
                "<D:propstat>"
                "<D:prop>"
                + "".join(props) +
                "</D:prop>"
                "<D:status>HTTP/1.1 200 OK</D:status>"
                "</D:propstat>"
                "</D:response>"
            )

        def do_OPTIONS(self):
            self.send_response(200)
            self.send_webdav_headers()
            self.send_header('Content-Length', '0')
            self.end_headers()

        def do_PROPFIND(self):
            kind, path_title, prefix = self._parse_path()
            depth = self.headers.get('Depth', '1')
            include_children = depth != '0'

            try:
                responses = []
                if kind == 'root':
                    root_href = '/'
                    try:
                        mtime = os.path.getmtime(wiki_path)
                        root_modified = format_http_date(datetime.fromtimestamp(mtime, tz=timezone.utc))
                    except OSError:
                        root_modified = format_http_date(None)

                    responses.append(
                        self._prop_response(
                            root_href,
                            displayname="wiki",
                            is_collection=True,
                            length=0,
                            modified=root_modified,
                            content_type=None
                        )
                    )

                    if include_children:
                        responses.append(
                            self._prop_response(
                                '/tiddlers/',
                                displayname="tiddlers",
                                is_collection=True,
                                length=0,
                                modified=root_modified,
                                content_type=None
                            )
                        )
                elif kind == 'scratch_collection':
                    collection_href = path_title
                    if not collection_href.endswith('/'):
                        collection_href = collection_href + '/'
                    displayname = collection_href.strip('/').split('/')[-1]
                    responses.append(
                        self._prop_response(
                            collection_href,
                            displayname=displayname,
                            is_collection=True,
                            length=0,
                            modified=format_http_date(None),
                            content_type=None
                        )
                    )
                    if include_children:
                        for scratch_path, content in scratch_files.items():
                            if not scratch_path.startswith(collection_href):
                                continue
                            name = urllib.parse.unquote(scratch_path.rstrip('/').split('/')[-1])
                            responses.append(
                                self._prop_response(
                                    scratch_path,
                                    displayname=name,
                                    is_collection=False,
                                    length=len(content),
                                    modified=format_http_date(None),
                                    content_type='application/octet-stream'
                                )
                            )
                elif kind == 'scratch_file':
                    href = urllib.parse.urlparse(self.path).path
                    name = urllib.parse.unquote(href.rstrip('/').split('/')[-1])
                    content = scratch_files.get(path_title, b'')
                    responses.append(
                        self._prop_response(
                            href,
                            displayname=name,
                            is_collection=False,
                            length=len(content),
                            modified=format_http_date(None),
                            content_type='application/octet-stream'
                        )
                    )
                elif kind == 'collection':
                    collection_href = prefix
                    if not collection_href.endswith('/'):
                        collection_href = collection_href + '/'
                    try:
                        mtime = os.path.getmtime(wiki_path)
                        collection_modified = format_http_date(datetime.fromtimestamp(mtime, tz=timezone.utc))
                    except OSError:
                        collection_modified = format_http_date(None)

                    displayname = "tiddlers" if collection_href == '/tiddlers/' else collection_href.strip('/').split('/')[-1]
                    responses.append(
                        self._prop_response(
                            collection_href,
                            displayname=displayname,
                            is_collection=True,
                            length=0,
                            modified=collection_modified,
                            content_type=None
                        )
                    )

                    if include_children and collection_href == '/tiddlers/':
                        tiddlers = self._load_tiddlers()
                        tiddlers.sort(key=lambda t: t.get('title', ''))
                        for tiddler in tiddlers:
                            tiddler_title = tiddler.get('title')
                            if not tiddler_title:
                                continue
                            content = format_tiddler_cat(tiddler)
                            content_length = len(content.encode('utf-8'))
                            modified = format_http_date(tiddler.get('modified') or tiddler.get('created'))
                            responses.append(
                                self._prop_response(
                                    self._href_for_title(tiddler_title, prefix=collection_href),
                                    displayname=tiddler_title,
                                    is_collection=False,
                                    length=content_length,
                                    modified=modified,
                                    content_type='text/plain; charset=utf-8'
                                )
                            )
                else:
                    try:
                        resolved_title = self._resolve_title(path_title)
                    except ValueError as e:
                        self.send_error(409, str(e))
                        return

                    tiddler = self._get_tiddler(resolved_title)
                    if not tiddler:
                        self.send_error(404, 'Tiddler not found')
                        return
                    content = format_tiddler_cat(tiddler)
                    content_length = len(content.encode('utf-8'))
                    modified = format_http_date(tiddler.get('modified') or tiddler.get('created'))
                    responses.append(
                        self._prop_response(
                            self._href_for_title(resolved_title, prefix=prefix),
                            displayname=resolved_title,
                            is_collection=False,
                            length=content_length,
                            modified=modified,
                            content_type='text/plain; charset=utf-8'
                        )
                    )

                xml_body = (
                    '<?xml version="1.0" encoding="utf-8"?>'
                    '<D:multistatus xmlns:D="DAV:">'
                    + "".join(responses) +
                    '</D:multistatus>'
                )
                self._send_xml(xml_body, status=207)
            except RuntimeError as e:
                self.send_error(500, str(e))

        def do_GET(self):
            kind, path_title, _ = self._parse_path()

            try:
                if kind == 'root':
                    body = "WebDAV root. Browse /tiddlers/ for tiddlers."
                    self._send_text(body, status=200)
                    return
                if kind == 'scratch_collection':
                    self._send_text('', status=200)
                    return
                if kind == 'scratch_file':
                    content = scratch_files.get(path_title, b'')
                    self._send_bytes(content, status=200)
                    return
                if kind == 'collection':
                    if _ == '/tiddlers/':
                        titles = self._load_tiddlers(titles_only=True)
                        titles.sort()
                        body = '\n'.join(titles)
                    else:
                        body = ''
                    self._send_text(body, status=200)
                    return

                try:
                    resolved_title = self._resolve_title(path_title)
                except ValueError as e:
                    self.send_error(409, str(e))
                    return

                tiddler = self._get_tiddler(resolved_title)
                if not tiddler:
                    self.send_error(404, 'Tiddler not found')
                    return

                content = format_tiddler_cat(tiddler)
                modified = format_http_date(tiddler.get('modified') or tiddler.get('created'))
                self._send_text(content, status=200, last_modified=modified)
            except RuntimeError as e:
                self.send_error(500, str(e))

        def do_HEAD(self):
            kind, path_title, _ = self._parse_path()

            try:
                if kind == 'root':
                    body = "WebDAV root. Browse /tiddlers/ for tiddlers."
                    self._send_text(body, status=200, include_body=False)
                    return
                if kind == 'scratch_collection':
                    self._send_text('', status=200, include_body=False)
                    return
                if kind == 'scratch_file':
                    content = scratch_files.get(path_title, b'')
                    self._send_bytes(content, status=200, include_body=False)
                    return
                if kind == 'collection':
                    if _ == '/tiddlers/':
                        titles = self._load_tiddlers(titles_only=True)
                        titles.sort()
                        body = '\n'.join(titles)
                    else:
                        body = ''
                    self._send_text(body, status=200, include_body=False)
                    return

                try:
                    resolved_title = self._resolve_title(path_title)
                except ValueError as e:
                    self.send_error(409, str(e))
                    return

                tiddler = self._get_tiddler(resolved_title)
                if not tiddler:
                    self.send_error(404, 'Tiddler not found')
                    return

                content = format_tiddler_cat(tiddler)
                modified = format_http_date(tiddler.get('modified') or tiddler.get('created'))
                self._send_text(content, status=200, include_body=False, last_modified=modified)
            except RuntimeError as e:
                self.send_error(500, str(e))

        def do_PUT(self):
            kind, path_title, _ = self._parse_path()
            if kind == 'scratch_file':
                if readonly:
                    self.send_error(403, 'Server is in readonly mode')
                    return
                length_header = self.headers.get('Content-Length')
                if length_header is None:
                    self.send_error(411, 'Content-Length required')
                    return
                try:
                    content_length = int(length_header)
                except ValueError:
                    self.send_error(400, 'Invalid Content-Length')
                    return
                body = b''
                if content_length > 0:
                    body = self.rfile.read(content_length)
                existing = path_title in scratch_files
                scratch_files[path_title] = body
                status = 204 if existing else 201
                self.send_response(status)
                self.send_webdav_headers()
                self.end_headers()
                return
            if kind != 'tiddler' or path_title is None:
                self.send_error(400, 'Missing tiddler title')
                return

            if readonly:
                self.send_error(403, 'Server is in readonly mode')
                return

            length_header = self.headers.get('Content-Length')
            if length_header is None:
                self.send_error(411, 'Content-Length required')
                return

            try:
                content_length = int(length_header)
            except ValueError:
                self.send_error(400, 'Invalid Content-Length')
                return

            body = b''
            if content_length > 0:
                body = self.rfile.read(content_length)

            try:
                content = body.decode('utf-8')
            except UnicodeDecodeError as e:
                self.send_error(400, f'Invalid UTF-8 encoding: {e}')
                return

            # Optimize: load titles only once instead of calling _resolve_title() and _get_tiddler()
            # which each load tiddlers separately
            try:
                titles_list = self._load_tiddlers(titles_only=True)
                titles = set(titles_list)  # Convert to set for O(1) lookup
            except RuntimeError as e:
                self.send_error(500, str(e))
                return

            # Decode the URL-encoded path to get the actual title
            resolved_title = decode_tiddler_title_from_path(path_title)
            existing = resolved_title in titles

            # Parse and prepare tiddler
            tiddler = parse_cat_content(content)
            tiddler['title'] = resolved_title
            tiddler_json = json.dumps(tiddler, ensure_ascii=False)

            try:
                with contextlib.redirect_stdout(io.StringIO()):
                    insert_tiddler(wiki_path, tiddler_json)
                status = 204 if existing else 201
                action = "Updated" if existing else "Created"
                verbose_print(f"[WebDAV PUT] {action} tiddler: {resolved_title}")
                self.send_response(status)
                self.send_webdav_headers()
                self.end_headers()
            except RuntimeError as e:
                self.send_error(500, str(e))
            except SystemExit:
                self.send_error(500, 'Error writing tiddler')

        def do_DELETE(self):
            kind, path_title, _ = self._parse_path()
            if kind == 'scratch_file':
                if readonly:
                    self.send_error(403, 'Server is in readonly mode')
                    return
                scratch_files.pop(path_title, None)
                self.send_response(204)
                self.send_webdav_headers()
                self.end_headers()
                return
            if kind == 'scratch_collection':
                if readonly:
                    self.send_error(403, 'Server is in readonly mode')
                    return
                prefix = path_title if path_title.endswith('/') else path_title + '/'
                for key in list(scratch_files.keys()):
                    if key.startswith(prefix):
                        scratch_files.pop(key, None)
                mkcol_paths.discard(prefix)
                self.send_response(204)
                self.send_webdav_headers()
                self.end_headers()
                return
            if kind == 'collection':
                if readonly:
                    self.send_error(403, 'Server is in readonly mode')
                    return
                if path_title in ('/', '/tiddlers/'):
                    self.send_error(405, 'Cannot delete collection')
                    return
                prefix = path_title if path_title.endswith('/') else path_title + '/'
                for key in list(scratch_files.keys()):
                    if key.startswith(prefix):
                        scratch_files.pop(key, None)
                mkcol_paths.discard(prefix)
                self.send_response(204)
                self.send_webdav_headers()
                self.end_headers()
                return
            if kind != 'tiddler' or path_title is None:
                self.send_error(400, 'Missing tiddler title')
                return

            if readonly:
                self.send_error(403, 'Server is in readonly mode')
                return

            try:
                try:
                    resolved_title = self._resolve_title(path_title)
                except ValueError as e:
                    self.send_error(409, str(e))
                    return

                tiddler = self._get_tiddler(resolved_title)
                if not tiddler:
                    self.send_error(404, 'Tiddler not found')
                    return

                with contextlib.redirect_stdout(io.StringIO()):
                    remove_tiddler(wiki_path, resolved_title)
                verbose_print(f"[WebDAV DELETE] Removed tiddler: {resolved_title}")
                self.send_response(204)
                self.send_webdav_headers()
                self.end_headers()
            except RuntimeError as e:
                self.send_error(500, str(e))
            except SystemExit:
                self.send_error(500, 'Error deleting tiddler')

        def do_LOCK(self):
            # Read and discard request body if present (WebDAV LOCK requests often include XML)
            content_length = self.headers.get('Content-Length')
            if content_length:
                try:
                    length = int(content_length)
                    if length > 0:
                        # Read and discard the lock request body
                        self.rfile.read(length)
                except (ValueError, OSError):
                    pass

            parsed = urllib.parse.urlparse(self.path)
            path = parsed.path or '/'
            if not path.startswith('/'):
                path = '/' + path
            lock_path = normalize_collection_path(path) if path.endswith('/') else path

            token = "opaquelocktoken:" + str(uuid.uuid4())
            lock_tokens[lock_path] = token

            xml_body = (
                '<?xml version="1.0" encoding="utf-8"?>'
                '<D:prop xmlns:D="DAV:">'
                '<D:lockdiscovery>'
                '<D:activelock>'
                '<D:locktype><D:write/></D:locktype>'
                '<D:lockscope><D:exclusive/></D:lockscope>'
                '<D:depth>infinity</D:depth>'
                '<D:locktoken><D:href>' + escape(token) + '</D:href></D:locktoken>'
                '</D:activelock>'
                '</D:lockdiscovery>'
                '</D:prop>'
            )

            body_bytes = xml_body.encode('utf-8')
            self.send_response(200)
            self.send_webdav_headers()
            self.send_header('Content-Type', 'application/xml; charset=utf-8')
            self.send_header('Content-Length', str(len(body_bytes)))
            self.send_header('Lock-Token', f"<{token}>")
            self.end_headers()
            self.wfile.write(body_bytes)

        def do_UNLOCK(self):
            token = self.headers.get('Lock-Token') or ''
            token = token.strip('<>')
            for key, value in list(lock_tokens.items()):
                if value == token:
                    del lock_tokens[key]
                    break
            self.send_response(204)
            self.send_webdav_headers()
            self.end_headers()

        def do_MKCOL(self):
            # Read and discard request body if present (MKCOL should have empty body per RFC but some clients send one)
            content_length = self.headers.get('Content-Length')
            if content_length:
                try:
                    length = int(content_length)
                    if length > 0:
                        # Read and discard any request body
                        self.rfile.read(length)
                except (ValueError, OSError):
                    pass

            parsed = urllib.parse.urlparse(self.path)
            path = parsed.path or '/'
            if not path.startswith('/'):
                path = '/' + path
            if path in ('', '/'):
                self.send_error(405, 'Collection exists')
                return
            collection_path = normalize_collection_path(path)
            if collection_path == '/tiddlers/':
                self.send_error(405, 'Collection exists')
                return
            if collection_path in mkcol_paths:
                self.send_error(405, 'Collection exists')
                return
            mkcol_paths.add(collection_path)
            self.send_response(201)
            self.send_webdav_headers()
            self.end_headers()

    try:
        server = HTTPServer((host, port), WebDavHandler)
        if readonly:
            verbose_print(f"Serving WebDAV at http://{host}:{port} (READONLY MODE)")
        else:
            verbose_print(f"Serving WebDAV at http://{host}:{port}")
        verbose_print(f"Wiki file: {wiki_path}")
        if readonly:
            verbose_print("Mode: READONLY - write attempts will be rejected")
        verbose_print("Press Ctrl+C to stop the server")
        server.serve_forever()
    except KeyboardInterrupt:
        verbose_print("\nServer stopped")
        sys.exit(0)
    except OSError as e:
        if e.errno == 48 or e.errno == 98:  # Address already in use
            print(f"Error: Port {port} is already in use", file=sys.stderr)
        else:
            print(f"Error starting server: {e}", file=sys.stderr)
        sys.exit(1)

def show_help():
    """Display usage information"""
    print("Usage: tw [--verbose] [<wiki_path>] <command> [args]", file=sys.stderr)
    print("", file=sys.stderr)
    print("Global options:", file=sys.stderr)
    print("  -v, --verbose               - Enable verbose output", file=sys.stderr)
    print("", file=sys.stderr)
    print("Commands:", file=sys.stderr)
    print("  init <dest_path>            - Create a new empty wiki", file=sys.stderr)
    print("  ls                          - List all tiddlers", file=sys.stderr)
    print("  cat <tiddler>               - Display tiddler contents", file=sys.stderr)
    print("  edit <tiddler>              - Edit tiddler in $EDITOR", file=sys.stderr)
    print("  json <tiddler> [...]        - Output tiddler(s) as JSON (--all for all tiddlers)", file=sys.stderr)
    print("  get <tiddler> <field>       - Get a specific field value", file=sys.stderr)
    print("  set <tiddler> <field> <val> - Set a field value", file=sys.stderr)
    print("  rm <tiddler>                - Remove a tiddler", file=sys.stderr)
    print("  touch <tiddler> [text]      - Create or update a tiddler", file=sys.stderr)
    print("  insert <json>               - Insert/replace tiddler(s) from JSON", file=sys.stderr)
    print("  replace <content>           - Insert/replace from cat format", file=sys.stderr)
    print("  append <tiddler> [text]     - Append text to tiddler", file=sys.stderr)
    print("  detect                      - Detect wiki format (modern or legacy)", file=sys.stderr)
    print("  export-dir <dir> [options]  - Export tiddlers to lossless markdown files", file=sys.stderr)
    print("  import-dir <dir> [options]  - Import tiddlers from markdown files", file=sys.stderr)
    print("  filetype-map                - Output MIME type to filetype mapping as JSON", file=sys.stderr)
    print("  mimetype <filename>         - Get MIME type for a file extension", file=sys.stderr)
    print("  install_plugin              - Install live reload plugin", file=sys.stderr)
    print("  ops [--op ...]              - Run multiple wiki operations sequentially", file=sys.stderr)
    print("  serve [options]             - Serve wiki locally (--host, --port, --readonly)", file=sys.stderr)
    print("  webdav [options]            - Serve tiddlers via WebDAV (--host, --port, --readonly)", file=sys.stderr)
    print("  filter <expression>         - Evaluate a TiddlyWiki filter expression", file=sys.stderr)
    print("", file=sys.stderr)
    print("Ops format:", file=sys.stderr)
    print("  tw <wiki> ops --op <command> [args] --op <command> [args] ...", file=sys.stderr)
    print("", file=sys.stderr)
    print("Export options:", file=sys.stderr)
    print("  --filter EXPR               - Export only tiddlers matching filter expression", file=sys.stderr)
    print("  --coerce-markdown           - Emit markdown-friendly body while preserving original payload", file=sys.stderr)
    print("  --force                     - Overwrite existing files in destination directory", file=sys.stderr)
    print("  --include-system            - Include system tiddlers (titles starting with $:/)", file=sys.stderr)
    print("", file=sys.stderr)
    print("Import options:", file=sys.stderr)
    print("  --mode MODE                 - upsert (default), replace, create-only", file=sys.stderr)
    print("  --delete-missing            - Delete wiki tiddlers not present in import dir (upsert mode)", file=sys.stderr)
    print("  --dry-run                   - Validate and report changes without writing wiki", file=sys.stderr)

def parse_global_flags(argv):
    verbose = False
    args = []
    parsing_flags = True
    for arg in argv:
        if parsing_flags and arg == "--":
            parsing_flags = False
            continue
        if parsing_flags and arg in ("-v", "--verbose"):
            verbose = True
            continue
        args.append(arg)
    return verbose, args

def command_mutates_wiki(command):
    return command in MUTATING_COMMANDS

def parse_server_args(args, default_port, command_name):
    host = 'localhost'
    port = default_port
    readonly = False

    i = 0
    while i < len(args):
        if args[i] == '--host' and i + 1 < len(args):
            host = args[i + 1]
            i += 2
        elif args[i] == '--port' and i + 1 < len(args):
            try:
                port = int(args[i + 1])
            except ValueError:
                print(f"Error: Invalid port number '{args[i + 1]}'", file=sys.stderr)
                sys.exit(1)
            i += 2
        elif args[i] == '--readonly':
            readonly = True
            i += 1
        else:
            print(f"Error: Unknown argument '{args[i]}'", file=sys.stderr)
            print(f"Usage: tw [<wiki_path>] {command_name} [--host HOST] [--port PORT] [--readonly]", file=sys.stderr)
            sys.exit(1)

    return host, port, readonly

def run_single_command(command, command_args, wiki_path=None, allow_stdin=True):
    if command == "init":
        if len(command_args) < 1:
            print("Error: init command requires a destination path", file=sys.stderr)
            sys.exit(1)
        init_wiki(command_args[0])
        return

    if command == "filetype-map":
        import json
        print(json.dumps(MIME_TO_VIM_FILETYPE, ensure_ascii=False))
        return

    if command == "mimetype":
        if len(command_args) < 1:
            print("Error: mimetype command requires a filename", file=sys.stderr)
            sys.exit(1)
        filename = command_args[0]
        _, ext = os.path.splitext(filename)
        ext = ext.lower()
        mime_type = EXT_TO_MIME_TYPE.get(ext, 'application/octet-stream')
        print(mime_type)
        return

    if not wiki_path:
        print("Error: Wiki path not provided", file=sys.stderr)
        sys.exit(1)

    if command == "ls":
        list_tiddlers(wiki_path)
    elif command == "cat":
        if len(command_args) < 1:
            print("Error: cat command requires a tiddler name", file=sys.stderr)
            sys.exit(1)
        cat_tiddler(wiki_path, command_args[0])
    elif command == "edit":
        if len(command_args) < 1:
            print("Error: edit command requires a tiddler name", file=sys.stderr)
            sys.exit(1)
        edit_tiddler(wiki_path, command_args[0])
    elif command == "json":
        if len(command_args) >= 1 and command_args[0] == "--all":
            json_tiddler(wiki_path, export_all=True)
        elif len(command_args) < 1:
            print("Error: json command requires at least one tiddler name or --all flag", file=sys.stderr)
            sys.exit(1)
        else:
            json_tiddler(wiki_path, *command_args)
    elif command == "get":
        if len(command_args) < 2:
            print("Error: get command requires a tiddler name and field name", file=sys.stderr)
            sys.exit(1)
        get_tiddler_field(wiki_path, command_args[0], command_args[1])
    elif command == "set":
        if len(command_args) < 3:
            print("Error: set command requires a tiddler name, field name, and value", file=sys.stderr)
            sys.exit(1)
        set_tiddler_field(wiki_path, command_args[0], command_args[1], command_args[2])
    elif command == "rm":
        if len(command_args) < 1:
            print("Error: rm command requires a tiddler name", file=sys.stderr)
            sys.exit(1)
        remove_tiddler(wiki_path, command_args[0])
    elif command == "touch":
        if len(command_args) < 1:
            print("Error: touch command requires a tiddler name", file=sys.stderr)
            sys.exit(1)
        text = command_args[1] if len(command_args) > 1 else ""
        touch_tiddler(wiki_path, command_args[0], text)
    elif command == "insert":
        if len(command_args) >= 1:
            tiddler_json = command_args[0]
        elif allow_stdin:
            tiddler_json = sys.stdin.read()
            if not tiddler_json:
                print("Error: insert command requires JSON string or stdin input", file=sys.stderr)
                sys.exit(1)
        else:
            print("Error: insert command requires explicit JSON when used in ops", file=sys.stderr)
            sys.exit(1)
        insert_tiddler(wiki_path, tiddler_json)
    elif command == "replace":
        if len(command_args) >= 1:
            content = command_args[0]
        elif allow_stdin:
            content = sys.stdin.read()
            if not content:
                print("Error: replace command requires content string or stdin input", file=sys.stderr)
                sys.exit(1)
        else:
            print("Error: replace command requires explicit content when used in ops", file=sys.stderr)
            sys.exit(1)
        replace_tiddler(wiki_path, content)
    elif command == "append":
        if len(command_args) < 1:
            print("Error: append command requires a tiddler name", file=sys.stderr)
            sys.exit(1)
        tiddler_title = command_args[0]
        if len(command_args) > 1:
            append_tiddler(wiki_path, tiddler_title, ' '.join(command_args[1:]))
        elif allow_stdin:
            append_tiddler(wiki_path, tiddler_title)
        else:
            print("Error: append command requires explicit text when used in ops", file=sys.stderr)
            sys.exit(1)
    elif command == "detect":
        if is_remote_wiki(wiki_path):
            content = read_wiki_content(wiki_path)
            format_type = detect_wiki_format(content)
        else:
            format_type = detect_format_streaming(wiki_path)
        print(format_type)
    elif command == "export-dir":
        if len(command_args) < 1:
            print("Error: export-dir command requires a destination directory", file=sys.stderr)
            sys.exit(1)

        dest_dir = command_args[0]
        filter_expr = None
        coerce_markdown = False
        force = False
        include_system = False

        i = 1
        while i < len(command_args):
            if command_args[i] == '--filter' and i + 1 < len(command_args):
                filter_expr = command_args[i + 1]
                i += 2
            elif command_args[i] == '--coerce-markdown':
                coerce_markdown = True
                i += 1
            elif command_args[i] == '--force':
                force = True
                i += 1
            elif command_args[i] == '--include-system':
                include_system = True
                i += 1
            else:
                print(f"Error: Unknown argument '{command_args[i]}'", file=sys.stderr)
                print("Usage: tw [<wiki_path>] export-dir <dir> [--filter EXPR] [--coerce-markdown] [--force] [--include-system]", file=sys.stderr)
                sys.exit(1)

        export_tiddlers_to_dir(
            wiki_path,
            dest_dir,
            filter_expr=filter_expr,
            coerce_markdown=coerce_markdown,
            force=force,
            include_system=include_system,
        )
    elif command == "import-dir":
        if len(command_args) < 1:
            print("Error: import-dir command requires a source directory", file=sys.stderr)
            sys.exit(1)

        source_dir = command_args[0]
        mode = 'upsert'
        delete_missing = False
        dry_run = False

        i = 1
        while i < len(command_args):
            if command_args[i] == '--mode' and i + 1 < len(command_args):
                mode = command_args[i + 1]
                i += 2
            elif command_args[i] == '--delete-missing':
                delete_missing = True
                i += 1
            elif command_args[i] == '--dry-run':
                dry_run = True
                i += 1
            else:
                print(f"Error: Unknown argument '{command_args[i]}'", file=sys.stderr)
                print("Usage: tw [<wiki_path>] import-dir <dir> [--mode MODE] [--delete-missing] [--dry-run]", file=sys.stderr)
                sys.exit(1)

        import_tiddlers_from_dir(
            wiki_path,
            source_dir,
            mode=mode,
            delete_missing=delete_missing,
            dry_run=dry_run
        )
    elif command == "install_plugin":
        install_live_reload_plugin(wiki_path)
    elif command == "serve":
        host, port, readonly = parse_server_args(command_args, default_port=8080, command_name="serve")
        serve_wiki(wiki_path, host, port, readonly)
    elif command == "webdav":
        host, port, readonly = parse_server_args(command_args, default_port=8081, command_name="webdav")
        serve_webdav(wiki_path, host, port, readonly)
    elif command == "filter":
        if len(command_args) < 1:
            print("Error: filter command requires an expression", file=sys.stderr)
            sys.exit(1)
        tw_filter.filter_command(command_args[0], wiki_path=wiki_path)
    else:
        print(f"Error: Unknown command '{command}'", file=sys.stderr)
        sys.exit(1)

def parse_ops_arguments(raw_args):
    operations = []
    current = []
    expecting_command = False

    for arg in raw_args:
        if arg == "--op":
            if expecting_command:
                print("Error: Empty operation after --op", file=sys.stderr)
                sys.exit(1)
            if current:
                operations.append(current)
                current = []
            expecting_command = True
            continue

        current.append(arg)
        expecting_command = False

    if expecting_command:
        print("Error: Empty operation after --op", file=sys.stderr)
        sys.exit(1)

    if current:
        operations.append(current)

    if not operations:
        print("Error: ops requires at least one operation", file=sys.stderr)
        sys.exit(1)

    parsed = []
    for op in operations:
        if not op:
            print("Error: Empty operation in ops", file=sys.stderr)
            sys.exit(1)
        parsed.append((op[0], op[1:]))
    return parsed

def load_ops_state(wiki_path):
    """Load wiki once for transactional ops execution."""
    ensure_local_wiki(wiki_path)

    with open(wiki_path, 'r', encoding='utf-8') as f:
        content = f.read()

    wiki_format = detect_wiki_format(content)

    state = {
        "wiki_path": wiki_path,
        "wiki_format": wiki_format,
        "content": content,
    }

    if wiki_format == 'modern':
        stores = extract_tiddler_stores(content)
        if not stores:
            print("Error: Could not find any tiddler stores in wiki", file=sys.stderr)
            sys.exit(1)

        for store in stores:
            for tiddler in store['tiddlers']:
                if 'title' in tiddler:
                    record_field_order(wiki_path, tiddler['title'], list(tiddler.keys()))

        state["stores"] = stores
    else:
        tiddlers = extract_legacy_tiddlers(content)
        if not tiddlers:
            print("Error: Could not find any tiddlers in wiki", file=sys.stderr)
            sys.exit(1)

        for tiddler in tiddlers:
            if 'title' in tiddler:
                record_field_order(wiki_path, tiddler['title'], list(tiddler.keys()))

        state["tiddlers"] = tiddlers

    return state

def ops_state_all_tiddlers(state):
    if state["wiki_format"] == 'modern':
        all_tiddlers = []
        for store in state["stores"]:
            all_tiddlers.extend(store['tiddlers'])
        return all_tiddlers
    return state["tiddlers"]

def ops_state_find_first_tiddler(state, tiddler_title):
    if state["wiki_format"] == 'modern':
        for store in state["stores"]:
            for tiddler in store['tiddlers']:
                if tiddler.get('title') == tiddler_title:
                    return store, tiddler
    else:
        for tiddler in state["tiddlers"]:
            if tiddler.get('title') == tiddler_title:
                return None, tiddler
    return None, None

def ops_state_insert_tiddlers(state, tiddlers_to_insert):
    """Insert/replace tiddlers in-memory using insert_tiddler semantics."""
    replaced_titles = []
    inserted_titles = []

    for i, tiddler in enumerate(tiddlers_to_insert):
        if not isinstance(tiddler, dict):
            print(f"Error: Array element {i} is not a valid tiddler object", file=sys.stderr)
            sys.exit(1)
        if 'title' not in tiddler:
            print(f"Error: Array element {i} is missing required 'title' field", file=sys.stderr)
            sys.exit(1)

    for new_tiddler in tiddlers_to_insert:
        if 'created' not in new_tiddler:
            new_tiddler['created'] = get_tiddlywiki_timestamp()
        if 'modified' not in new_tiddler:
            new_tiddler['modified'] = get_tiddlywiki_timestamp()

        tiddler_title = new_tiddler['title']

        if state["wiki_format"] == 'modern':
            found = False
            for store in state["stores"]:
                original_count = len(store['tiddlers'])
                store['tiddlers'] = [t for t in store['tiddlers'] if t.get('title') != tiddler_title]
                if len(store['tiddlers']) < original_count:
                    found = True

            state["stores"][0]['tiddlers'].append(new_tiddler)
        else:
            found = False
            for idx, existing in enumerate(state["tiddlers"]):
                if existing.get('title') == tiddler_title:
                    state["tiddlers"][idx] = new_tiddler
                    found = True
                    break
            if not found:
                state["tiddlers"].append(new_tiddler)

        if found:
            replaced_titles.append(tiddler_title)
        else:
            inserted_titles.append(tiddler_title)

    for title in replaced_titles:
        verbose_print(f"Replaced tiddler: {title}")
    for title in inserted_titles:
        verbose_print(f"Inserted tiddler: {title}")

def ops_state_set_field(state, tiddler_title, field_name, field_value):
    store, tiddler = ops_state_find_first_tiddler(state, tiddler_title)

    is_new_tiddler = False
    if not tiddler:
        tiddler = {"title": tiddler_title}
        is_new_tiddler = True
        if state["wiki_format"] == 'modern':
            state["stores"][0]['tiddlers'].append(tiddler)
        else:
            state["tiddlers"].append(tiddler)
        verbose_print(f"Created tiddler: {tiddler_title}")

    old_value = tiddler.get(field_name)
    field_changed = (old_value != field_value)
    tiddler[field_name] = field_value

    if is_new_tiddler or (field_changed and field_name not in ('modified', 'created')):
        ensure_timestamps(tiddler, is_modification=True)
    elif not is_new_tiddler:
        ensure_timestamps(tiddler, is_modification=False)

    verbose_print(f"Set {field_name} = {field_value}")

def ops_state_touch_tiddler(state, tiddler_title, text=""):
    _, tiddler = ops_state_find_first_tiddler(state, tiddler_title)

    if tiddler:
        ensure_timestamps(tiddler, is_modification=True)
        if text:
            tiddler['text'] = text
        verbose_print(f"Updated tiddler: {tiddler_title}")
    else:
        new_tiddler = {"title": tiddler_title, "text": text}
        ensure_timestamps(new_tiddler, is_modification=True)
        if state["wiki_format"] == 'modern':
            state["stores"][0]['tiddlers'].append(new_tiddler)
        else:
            state["tiddlers"].append(new_tiddler)
        verbose_print(f"Created tiddler: {tiddler_title}")

def ops_state_remove_tiddler(state, tiddler_title):
    found = False

    if state["wiki_format"] == 'modern':
        for store in state["stores"]:
            original_count = len(store['tiddlers'])
            store['tiddlers'] = [t for t in store['tiddlers'] if t.get('title') != tiddler_title]
            if len(store['tiddlers']) < original_count:
                found = True
    else:
        original_count = len(state["tiddlers"])
        state["tiddlers"] = [t for t in state["tiddlers"] if t.get('title') != tiddler_title]
        found = len(state["tiddlers"]) < original_count

    if not found:
        print(f"Error: Tiddler '{tiddler_title}' not found", file=sys.stderr)
        sys.exit(1)

    verbose_print(f"Removed tiddler: {tiddler_title}")

def ops_state_append_tiddler(state, tiddler_title, text_to_append):
    all_tiddlers = ops_state_all_tiddlers(state)
    tiddler = None
    for item in all_tiddlers:
        if item.get('title') == tiddler_title:
            tiddler = item
            break

    if not tiddler:
        tiddler = {"title": tiddler_title, "text": text_to_append}
        ensure_timestamps(tiddler, is_modification=True)
        verbose_print(f"Created tiddler: {tiddler_title}")
    else:
        existing_text = tiddler.get('text', '')
        if existing_text:
            tiddler['text'] = existing_text + '\n' + text_to_append
        else:
            tiddler['text'] = text_to_append
        ensure_timestamps(tiddler, is_modification=True)

    # Keep append behavior consistent with append_tiddler -> insert_tiddler flow.
    ops_state_insert_tiddlers(state, [tiddler])

def commit_ops_state(state, wiki_path):
    """Write in-memory state once to disk."""
    import json

    if state["wiki_format"] == 'modern':
        replacements = []
        for store in state["stores"]:
            sorted_tiddlers = sorted(store['tiddlers'], key=lambda t: t.get('title', ''))
            tiddler_jsons = [
                json.dumps(
                    reorder_tiddler_fields(t, wiki_path, t.get('title', '')),
                    ensure_ascii=False,
                    separators=(',', ':')
                )
                for t in sorted_tiddlers
            ]
            new_json = '[\n' + ',\n'.join(tiddler_jsons) + '\n]'
            new_json = new_json.replace('<', '\\u003C')
            new_store = f'<script class="tiddlywiki-tiddler-store" type="application/json">{new_json}</script>'
            replacements.append((store['start'], store['end'], new_store))

        new_content = state["content"]
        for start, end, replacement in reversed(replacements):
            new_content = new_content[:start] + replacement + new_content[end:]
    else:
        import re

        content = state["content"]
        store_pattern = r'<div id="storeArea"[^>]*>'
        store_match = re.search(store_pattern, content)
        if not store_match:
            print("Error: Could not find storeArea in wiki", file=sys.stderr)
            sys.exit(1)

        store_start = store_match.start()
        div_open_pattern = re.compile(r'<div(?:\s+[^>]*)?>|</div>', re.DOTALL)
        div_count = 1
        store_end = None

        for match in div_open_pattern.finditer(content, store_match.end()):
            tag = match.group()
            if tag.startswith('</'):
                div_count -= 1
                if div_count == 0:
                    store_end = match.end()
                    break
            else:
                div_count += 1

        if store_end is None:
            print("Error: Could not find closing tag for storeArea", file=sys.stderr)
            sys.exit(1)

        new_store = build_legacy_store(state["tiddlers"])
        new_content = content[:store_start] + new_store + content[store_end:]

    temp_path = None
    try:
        fd, temp_path = tempfile.mkstemp(
            prefix='.tw-ops-',
            suffix='.tmp',
            dir=os.path.dirname(wiki_path) or '.'
        )
        with os.fdopen(fd, 'w', encoding='utf-8') as f:
            f.write(new_content)
        os.replace(temp_path, wiki_path)
    except Exception as e:
        print(f"Error: Failed to write wiki file: {e}", file=sys.stderr)
        sys.exit(1)
    finally:
        if temp_path and os.path.exists(temp_path):
            try:
                os.remove(temp_path)
            except OSError:
                pass

def run_transactional_ops_command(state, command, command_args):
    import json

    if command not in OPS_TRANSACTION_SUPPORTED_COMMANDS:
        print(f"Error: Command '{command}' is not supported in mutating ops batches", file=sys.stderr)
        sys.exit(1)

    if command == "ls":
        titles = [t.get('title', '') for t in ops_state_all_tiddlers(state) if 'title' in t]
        titles.sort()
        for title in titles:
            print(title)
    elif command == "cat":
        if len(command_args) < 1:
            print("Error: cat command requires a tiddler name", file=sys.stderr)
            sys.exit(1)
        _, tiddler = ops_state_find_first_tiddler(state, command_args[0])
        if not tiddler:
            print(f"Error: Tiddler '{command_args[0]}' not found", file=sys.stderr)
            sys.exit(1)
        print(format_tiddler_cat(tiddler))
    elif command == "json":
        all_tiddlers = ops_state_all_tiddlers(state)
        if len(command_args) >= 1 and command_args[0] == "--all":
            print(json.dumps(all_tiddlers, ensure_ascii=False))
        elif len(command_args) < 1:
            print("Error: json command requires at least one tiddler name or --all flag", file=sys.stderr)
            sys.exit(1)
        else:
            found_tiddlers = []
            for title in command_args:
                _, tiddler = ops_state_find_first_tiddler(state, title)
                if not tiddler:
                    print(f"Error: Tiddler '{title}' not found", file=sys.stderr)
                    sys.exit(1)
                found_tiddlers.append(tiddler)

            if len(found_tiddlers) == 1:
                print(json.dumps(found_tiddlers[0], indent=2, ensure_ascii=False))
            else:
                print(json.dumps(found_tiddlers, indent=2, ensure_ascii=False))
    elif command == "get":
        if len(command_args) < 2:
            print("Error: get command requires a tiddler name and field name", file=sys.stderr)
            sys.exit(1)
        _, tiddler = ops_state_find_first_tiddler(state, command_args[0])
        if not tiddler:
            print(f"Error: Tiddler '{command_args[0]}' not found", file=sys.stderr)
            sys.exit(1)
        field_name = command_args[1]
        if field_name not in tiddler:
            print(f"Error: Field '{field_name}' not found in tiddler '{command_args[0]}'", file=sys.stderr)
            sys.exit(1)
        print(tiddler[field_name])
    elif command == "set":
        if len(command_args) < 3:
            print("Error: set command requires a tiddler name, field name, and value", file=sys.stderr)
            sys.exit(1)
        ops_state_set_field(state, command_args[0], command_args[1], command_args[2])
    elif command == "rm":
        if len(command_args) < 1:
            print("Error: rm command requires a tiddler name", file=sys.stderr)
            sys.exit(1)
        ops_state_remove_tiddler(state, command_args[0])
    elif command == "touch":
        if len(command_args) < 1:
            print("Error: touch command requires a tiddler name", file=sys.stderr)
            sys.exit(1)
        text = command_args[1] if len(command_args) > 1 else ""
        ops_state_touch_tiddler(state, command_args[0], text)
    elif command == "insert":
        if len(command_args) < 1:
            print("Error: insert command requires explicit JSON when used in ops", file=sys.stderr)
            sys.exit(1)
        try:
            parsed_json = json.loads(command_args[0])
        except json.JSONDecodeError as e:
            print(f"Error: Invalid JSON: {e}", file=sys.stderr)
            sys.exit(1)

        if isinstance(parsed_json, dict):
            tiddlers_to_insert = [parsed_json]
        elif isinstance(parsed_json, list):
            tiddlers_to_insert = parsed_json
        else:
            print("Error: JSON must be either an object (single tiddler) or an array (multiple tiddlers)", file=sys.stderr)
            sys.exit(1)

        ops_state_insert_tiddlers(state, tiddlers_to_insert)
    elif command == "replace":
        if len(command_args) < 1:
            print("Error: replace command requires explicit content when used in ops", file=sys.stderr)
            sys.exit(1)
        tiddler = parse_replace_content(command_args[0], update_modified=True)
        ops_state_insert_tiddlers(state, [tiddler])
    elif command == "append":
        if len(command_args) < 1:
            print("Error: append command requires a tiddler name", file=sys.stderr)
            sys.exit(1)
        if len(command_args) < 2:
            print("Error: append command requires explicit text when used in ops", file=sys.stderr)
            sys.exit(1)
        tiddler_title = command_args[0]
        text_to_append = ' '.join(command_args[1:])
        ops_state_append_tiddler(state, tiddler_title, text_to_append)
    elif command == "detect":
        print(state["wiki_format"])

def run_ops_command(wiki_path, raw_args):
    operations = parse_ops_arguments(raw_args)

    for command, _ in operations:
        if command in OPS_DISALLOWED_COMMANDS:
            print(f"Error: Command '{command}' is not supported inside ops", file=sys.stderr)
            sys.exit(1)

    mutating = any(command_mutates_wiki(command) for command, _ in operations)
    use_transaction = mutating and not is_remote_wiki(wiki_path)

    if use_transaction:
        state = load_ops_state(wiki_path)
        for op_index, (command, command_args) in enumerate(operations, start=1):
            try:
                run_transactional_ops_command(state, command, command_args)
            except SystemExit as e:
                code = e.code if isinstance(e.code, int) else 1
                print(f"Error: ops failed at operation {op_index} ('{command}')", file=sys.stderr)
                sys.exit(code)
        commit_ops_state(state, wiki_path)
        return

    # Non-mutating batches (or remote wiki batches) use regular command execution.
    for op_index, (command, command_args) in enumerate(operations, start=1):
        try:
            run_single_command(command, command_args, wiki_path=wiki_path, allow_stdin=False)
        except SystemExit as e:
            code = e.code if isinstance(e.code, int) else 1
            print(f"Error: ops failed at operation {op_index} ('{command}')", file=sys.stderr)
            sys.exit(code)

def main():
    global VERBOSE
    verbose, args = parse_global_flags(sys.argv[1:])
    VERBOSE = verbose

    if len(args) > 0 and args[0] in ('--help', '-h', 'help'):
        show_help()
        sys.exit(0)

    if len(args) < 1:
        show_help()
        sys.exit(1)

    arg_idx = 0
    wiki_path_arg = None

    if len(args) > 1:
        potential_path = args[0]
        if potential_path.endswith('.html') or os.path.exists(potential_path) or is_remote_wiki(potential_path):
            wiki_path_arg = potential_path
            arg_idx = 1

    command = args[arg_idx] if arg_idx < len(args) else None
    if not command:
        print("Error: No command provided", file=sys.stderr)
        sys.exit(1)

    if command in ('--help', '-h', 'help'):
        show_help()
        sys.exit(0)

    command_args = args[arg_idx + 1:]

    if command in NO_WIKI_COMMANDS:
        run_single_command(command, command_args, wiki_path=None)
        return

    wiki_path = get_wiki_path(wiki_path_arg)

    if command == "ops":
        run_ops_command(wiki_path, command_args)
        return

    run_single_command(command, command_args, wiki_path=wiki_path)

if __name__ == "__main__":
    main()
